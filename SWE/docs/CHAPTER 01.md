# What Is Software Engineering?

Written by Titus Winters
Edited by Tom Manshreck

石の上には何も建たない。すべては砂の上に建つが、その砂が石であるかのように建てなければならない。
-- ホルヘ・ルイス・ボルヘス

プログラミングとソフトウェアエンジニアリングの決定的な違いは、「時間」「規模」「トレードオフ」の3点です。ソフトウェアエンジニアリングのプロジェクトでは、エンジニアは時間の経過と最終的な変化の必要性をより意識する必要があります。また、ソフトウェアエンジニアリングの組織では、制作するソフトウェアだけでなく、それを制作している組織にとっても、規模と効率をより重視する必要があります。最後に、ソフトウェアエンジニアとしての私たちは、時間と成長の不正確な見積もりに基づいて、より複雑でリスクの高い決断をすることを求められます。

グーグルでは、「ソフトウェアエンジニアリングとは、時間をかけて統合されたプログラミングである」と言うことがあります。プログラミングは確かにソフトウェアエンジニアリングの重要な部分を占めています。そもそもプログラミングとは、新しいソフトウェアを生み出す方法です。この区別を受け入れるならば、プログラミングのタスク（開発）とソフトウェアエンジニアリングのタスク（開発、修正、メンテナンス）を区別する必要があるかもしれません。また、プログラミングに「時間」が加わることで、新たな側面が生まれます。立方体は四角形ではなく、距離は速度ではありません。ソフトウェアエンジニアリングはプログラミングではありません。

時間がプログラムに与える影響を考える一つの方法は、"あなたのコードの期待寿命(*1)はどれくらいですか？"という質問を考えることです。この質問に対する合理的な答えは、およそ10万分の1の差があります。数分しか持たないコードを考えるのも、何十年も持つコードを考えるのも同じように合理的です。一般的に、短いコードは時間に影響されません。1時間しか使えないプログラムのために、基盤となるライブラリやオペレーティングシステム（OS）、ハードウェア、言語のバージョンを変更する必要があることはまずありません。このような短命なシステムは、1次元に圧縮された立方体が正方形であるのと同じように、事実上「ただの」プログラミング問題である。その時間を拡大して寿命を長くすると、変化が重要になってきます。10年以上のスパンで見ると、暗黙的であれ明示的であれ、ほとんどのプログラムの依存関係は変化するでしょう。このような認識が、ソフトウェアエンジニアリングとプログラミングの違いの根底にあります。

この違いは、私たちがソフトウェアの持続可能性と呼んでいるものの核心です。想定されるソフトウェアの寿命の間、技術的な理由やビジネス上の理由など、価値のある変化に対応することができれば、そのプロジェクトは持続可能です。重要なのは、ここでは能力だけを見ていることです。価値がないとか、他の優先事項があるとかの理由で、あるアップグレードを実行しないという選択もあり得ます(*2)。根本的に技術や製品の方向性の変化に対応できないということは、そのような変化が重要になることはないという希望に、高いリスクを賭けていることになります。短期的なプロジェクトであれば、それは安全な賭けかもしれません。しかし、それが何十年も続くとなると、そうはいかないでしょう(*3)。

ソフトウェアエンジニアリングのもう一つの見方は、スケールを考えることです。何人の人が関わっているのか。また、開発やメンテナンスにどのような役割を果たしているのか。プログラミングの作業は個人で行うことが多いですが、ソフトウェアエンジニアリングの作業はチームで行います。ソフトウェアエンジニアリングを定義しようとした初期の試みでは、「多バージョンのプログラムを多人数で開発すること」という視点で適切な定義がなされています(*4)。このことから、ソフトウェアエンジニアリングとプログラミングの違いは、時間と人の違いであることがわかります。チームでの共同作業には新たな問題が発生しますが、一人のプログラマーが作るよりも価値のあるシステムを生み出す可能性があります。

チームの組織、プロジェクトの構成、ソフトウェアプロジェクトのポリシーとプラクティスのすべてが、ソフトウェアエンジニアリングの複雑さのこの側面を支配しています。これらの問題は規模に固有のものです。組織が大きくなり、そのプロジェクトが拡大するにつれて、ソフトウェアの生産効率は上がるのでしょうか。開発ワークフローは規模が大きくなるほど効率的になるのか、それともバージョン管理ポリシーやテスト戦略に比例してコストが高くなるのか。コミュニケーションや人間のスケールに関する問題は、ソフトウェア工学の黎明期から議論されており、「人月の神話」(*5)にまで遡ることができます。このようなスケールの問題は、しばしばポリシーの問題であり、ソフトウェアの持続可能性の問題の根幹をなすものです。

また、ソフトウェアエンジニアリングは、意思決定の複雑さとその利害関係の点で、プログラミングとは異なると言えます。ソフトウェアエンジニアリングでは、いくつかの進路の間のトレードオフを評価することを定期的に迫られますが、それは時に大きなリスクを伴い、また多くの場合、不完全な価値基準を用います。ソフトウェアエンジニア、またはソフトウェアエンジニアリングのリーダーの仕事は、組織、製品、および開発ワークフローのスケーリングコストの持続性と管理を目指すことです。これらのインプットを念頭に置いて、トレードオフを評価し、合理的な判断を下してください。時にはメンテナンスの変更を先延ばしにしたり、スケールメリットのないポリシーを採用することもあるかもしれませんが、その場合はその決定を見直す必要があることを知っておく必要があります。そのような選択をする際には、延期されるコストを明確にしておく必要があります。

ソフトウェアエンジニアリングの世界では、万能の解決策はめったにありませんが、この本も同じです。「このソフトウェアの寿命はどれくらいか」についての妥当な答えが10万分の1であったり、「あなたの組織には何人のエンジニアがいるか」についての答えが1万分の1であったり、「あなたのプロジェクトで利用可能な計算機資源はどれくらいか」についての答えが誰にもわからなかったりすると、Googleの経験はあなたの経験とは一致しないでしょう。この本では、何万人ものエンジニアと世界規模の計算機資源を使って、何十年も続くと予想されるソフトウェアを構築・保守する中で、私たちが見つけた効果的な方法を紹介することを目的としています。私たちがこの規模で必要だと感じた手法のほとんどは、小規模な取り組みにも有効です。これは、規模を拡大したときに良いと思われるエンジニアリングエコシステムについての報告と考えてください。いくつかの場所では、超大規模なスケールにはそれなりのコストがかかり、私たちは余分な間接費を払わない方が幸せだと考えています。そのような場合には、警告を発しています。願わくば、あなたの組織がそれらのコストを心配するほど大きくなったら、より良い答えを見つけてください。

チームワーク、文化、ポリシー、ツールなどの具体的な話に入る前に、まずは「時間」「規模」「トレードオフ」という主要なテーマについて詳しく説明します。

## 時間と変化

初心者がプログラミングを学んでいるとき、出来上がったコードの寿命は通常、数時間または数日で測られます。プログラミングの課題や演習では、一度書いただけで、リファクタリングはほとんど行われず、長期的なメンテナンスも行われません。これらのプログラムは、最初に作った後は、二度と作り直されたり実行されたりしないことが多いのです。これは教育現場では当然のことです。中等教育や高等教育の場では、チームプロジェクトのコースや実践的な論文があるかもしれません。もしそうであれば、学生のコードが1ヶ月ほどしか生きられないのは、そのようなプロジェクトだけでしょう。開発者は、要求の変化に応じてコードをリファクタリングする必要があるかもしれませんが、自分の環境の広範な変化に対応することを求められることはないでしょう。

また、一般的な業界環境でも、寿命の短いコードの開発者が見受けられます。モバイルアプリの寿命はかなり短く(*6)、良くも悪くも全面的な書き換えが比較的よく行われます。初期段階のスタートアップ企業のエンジニアは、長期的な投資よりも目先の目標を重視するのは当然かもしれません。新興企業の連続した開発者は、10年の開発経験があっても、1～2年以上の長期にわたって存在することが予想されるソフトウェアのメンテナンスをほとんど、あるいは全く経験していないということも十分あり得るのです。

一方で、成功したプロジェクトの中には、事実上、寿命に制限がないものもあります。Google検索、Linuxカーネル、Apache HTTP Serverプロジェクトのエンドポイントを合理的に予測することはできません。依存関係や言語バージョンなどのアップグレードがいつ必要になるかは予測できません。寿命が長くなると、これらの長寿プロジェクトは、プログラミングの課題やスタートアップの開発とは異なる雰囲気を持つようになります。

図1-1は、この「期待寿命」の両端に位置する2つのソフトウェアプロジェクトを示しています。期待寿命が数時間のタスクに取り組んでいるプログラマーにとって、どのような種類のメンテナンスを期待するのが妥当でしょうか。つまり、1回しか実行されないPythonスクリプトに取り組んでいる最中に、OSの新バージョンが出たら、やっていることをやめてアップグレードすべきでしょうか？もちろんそうではありません：アップグレードは重要ではありません。しかし、その反対に、Google検索が1990年代のOSのバージョンで止まっているとしたら、明らかに問題です。

![Fig 1-1](../img/Fig1-1.png)

期待寿命スペクトルの低いところと高いところを見ると、どこかに転換点があることがわかります。1回限りのプログラムと何十年も続くプロジェクトの間のどこかで、プロジェクトが外部性の変化に対応し始めなければならないという移行が起こるのです(*7)。最初からアップグレードを計画していなかったプロジェクトにとって、この移行は3つの理由で非常に苦痛なものとなります。

- このプロジェクトではまだ行われていない作業を行っていること、さらに隠れた前提条件が組み込まれていること。
- アップグレードを行おうとしているエンジニアが、この種の作業を経験していない可能性が高いこと。
- アップグレードの規模は通常よりも大きく、段階的なアップグレードではなく、数年分のアップグレードを一度に行うことが多い。

そのため、一度でもアップグレードを経験すると（あるいは途中で断念すると）、その後のアップグレードにかかるコストを過大評価して「二度とやらない」と決めてしまうのも無理はない。このような結論に達した企業は、結局、物を捨ててコードを書き直すか、二度とアップグレードしないことにしてしまいます。苦しい作業を避けるという自然な方法ではなく、苦しくないようにするための投資をすることが、より責任ある答えになることがあります。これは、アップグレードのコスト、それが提供する価値、プロジェクトの予想される寿命などによって異なります。

最初の大きなアップグレードを乗り越えるだけでなく、今後も確実に最新の状態を維持できるようにすることが、プロジェクトの長期的な持続可能性の本質なのです。持続可能性のためには、必要な変化の影響を計画し、管理することが必要です。Googleの多くのプロジェクトでは、試行錯誤を繰り返しながら、このような持続可能性を実現してきたと考えています。

では具体的に、短期的なプログラミングと、寿命の長いコードを作ることはどう違うのでしょうか。そのためには、"たまたま動く "ということと、"メンテナンスが可能である "ということの違いを、より深く認識する必要があります。これらの問題を特定する完璧なソリューションはありません。それは残念なことですが、ソフトウェアを長期的にメンテナンスできるようにすることは、常に戦いなのです。

## ハイラムの法則

もしあなたが他のエンジニアが使うプロジェクトを保守しているなら、「動作する」対「保守可能である」ことについての最も重要な教訓は、私たちが「ハイラムの法則」と呼ぶものです。

十分な数のAPIユーザーがいれば、契約書で何を約束したかは問題ではありません。

私たちの経験では、この公理は、時間の経過とともにソフトウェアを変化させることを議論する際の主要な要因となっています。概念的にはエントロピーに似ています。効率や熱力学の議論でエントロピーを意識しなければならないのと同様に、経年変化やメンテナンスの議論ではハイラムの法則(*8)を意識しなければなりません。エントロピーが絶対に減らないからといって、効率化を図ってはいけないということではありません。ソフトウェアを保守する際にハイラムの法則が適用されるからといって、それを想定したり、理解を深めたりすることができないわけではありません。私たちはそれを軽減することはできますが、根絶することはできないことを知っています。

ハイラムの法則は、最善の意図を持ち、最高のエンジニアを雇い、コードレビューをしっかりと行ったとしても、公表された契約やベストプラクティスを完全に遵守することはできないという実践的な知識を表しています。APIオーナーとしては、インターフェースの約束事を明確にすることで、ある程度の柔軟性や自由度を得ることができますが、実際には、ある変更の複雑さや難しさは、ユーザーがAPIの観察可能な動作をどれだけ便利だと感じるかにも依存します。ユーザーがそのようなものに依存できなければ、APIの変更は容易になります。十分な時間と十分なユーザーがいれば、最も無害な変更であっても何かが壊れる(*9)。その変更の価値を分析する際には、それらの壊れた部分を調査し、特定し、解決することの難しさを考慮しなければならない。

## 例 ハッシュの順序付け

ハッシュの反復順序付けの例を考えてみましょう。ハッシュベースの集合に5つの要素を挿入した場合、どのような順序で取り出すことができるでしょうか。

```
>>> for i in {"apple", "banana", "carrot", "durian", "eggplant"}: print(i)
...
durian
carrot
apple
eggplant
banana
```

ほとんどのプログラマーは、ハッシュテーブルが明らかに順序付けられていないことを知っている。しかし、使用しているハッシュテーブルが永遠にそのような順序を提供することを意図しているかどうか、詳細を知っている人は少ない。しかし、過去10～20年の間に、コンピュータ業界ではこのような型を使用する経験が進化してきました。

- ハッシュフラッディング(*10)攻撃により、非決定論的なハッシュ反復のインセンティブが高まっている。
- ハッシュアルゴリズムやハッシュコンテナの改良による効率化のためには、ハッシュの反復順序の変更が必要です。
- ハイラムの法則によれば、プログラマは、能力があれば、ハッシュテーブルのトラバース順序に依存したプログラムを書くことになります。

その結果、専門家に「ハッシュコンテナに特定の出力配列を仮定できますか」と質問すると、おそらく専門家は「いいえ」と答えるでしょう。大体においてそれは正しいのですが、おそらく単純化されています。もっとニュアンスのある答えは、「あなたのコードが、ハードウェア、言語ランタイム、データ構造の選択に変更がなく、短期間で終わるのであれば、そのような仮定は問題ない。「コードの寿命がわからない場合や、依存しているものが絶対に変わらないと約束できない場合は、そのような仮定は正しくありません。」 です。さらに、自分の実装がハッシュコンテナの順序に依存していなくても、暗黙的にそのような依存関係を作っている他のコードが使用している可能性もあります。例えば、ライブラリがRPC（Remote Procedure Call）レスポンスに値をシリアライズする場合、RPCの呼び出し元はこれらの値の順序に依存することになるかもしれません。

これは "動く "と "正しい "の違いを示す非常に基本的な例です。短期間のプログラムであれば、コンテナの反復順序に依存しても技術的な問題は発生しません。一方、ソフトウェアエンジニアリングのプロジェクトでは、定義された順序に依存することはリスクであり、十分な時間があれば、その反復順序を変更することに価値を見出すことができます。その価値とは、効率性やセキュリティ、あるいは将来の変更に備えたデータ構造など、様々な形で現れます。その価値が明らかになったら、その価値と、開発者や顧客が困ることとのトレードオフを比較検討する必要があります。

一部の言語では、依存性を防ぐために、ライブラリのバージョン間や同じプログラムの実行間でもハッシュの順序を特別にランダム化している。しかし、この方法でも「ハイラムの法則」のような驚きがあります。ハッシュの反復順序を非効率な乱数生成器として使用しているコードがあります。今、そのようなランダム性を取り除くと、そのユーザーは壊れてしまいます。熱力学的なシステムではエントロピーが増大するように、ハイラムの法則は観察可能なすべての行動に適用されます。

「今すぐ動く」と「いつまでも動く」という考え方で書かれたコードの違いを考えてみると、いくつかの明確な関係が見えてきます。コードを（非常に）可変的な寿命を必要とする人工物として見ると、プログラミングスタイルを分類することができます。脆弱で未公開の依存関係の機能に依存するコードは、「ハッキー」や「クレバー」と評される可能性が高く、一方、ベストプラクティスに沿って将来を計画したコードは、「クリーン」や「メンテナブル」と評される可能性が高くなります。どちらにも目的がありますが、どちらを選択するかは、コードの寿命に大きく依存します。私たちは、「"賢い "が褒め言葉であればプログラミングだが、"賢い "が非難の言葉であればソフトウェアエンジニアリングだ」と言っています。

## なぜ「何も変わらない」ことを目指さないのか？

時間や変化に対応する必要性についての議論には、「変化は必要かもしれない」という仮定が含まれています。そうでしょうか？

この本に書かれている他のすべてのことと同様に、それは場合によります。ここでは、「ほとんどのプロジェクトでは、十分に長い期間をかけて、その下にあるすべてのものを変更する必要があるかもしれない」ということを簡単に約束します。もしあなたのプロジェクトが純粋なCで書かれていて、外部依存がない（あるいはPOSIXのように長期的な安定性が約束されている外部依存しかない）ならば、どんな形のリファクタリングや難しいアップグレードも避けることができるかもしれません。C言語は安定性を提供するのに優れた仕事をしており、多くの点でそれが主な目的となっています。

多くのプロジェクトでは、基盤となる技術の変化にさらされることが多くあります。ほとんどのプログラミング言語やランタイムは、C言語よりもずっと変化します。純粋なC言語で実装されたライブラリであっても、新機能をサポートするために変更されることがあり、それが下流のユーザーに影響を与えることがあります。セキュリティの問題は、プロセッサ、ネットワークライブラリ、アプリケーションコードなど、あらゆる技術に開示されています。あなたのプロジェクトが依存しているすべての技術には、重大なバグやセキュリティ脆弱性が含まれている可能性があります（できれば小さい方がいい）。もし、Heartbleedのパッチを展開できなかったり、MeltdownやSpectreのような投機的実行の問題を軽減できなかったりするとしたら、それは大きな賭けです。

効率性の向上は、さらに事態を複雑にします。私たちは、データセンターに費用対効果の高いコンピューティング機器を装備し、特にCPUの効率を高めたいと考えています。しかし、初期のGoogleのアルゴリズムやデータ構造は、現代の機器では単純に効率が悪くなります。リンクリストやバイナリサーチツリーはまだ問題なく動作しますが、CPUサイクルとメモリレイテンシの差がますます大きくなり、「効率的な」コードがどのようなものかに影響を与えます。時間の経過とともに、ソフトウェアの設計変更を伴わない新しいハードウェアへのアップグレードの価値は低下してしまいます。下位互換性は、古いシステムが機能することを保証しますが、古い最適化が役に立つことを保証するものではありません。このような機会を利用しない、あるいは利用できない場合、大きなコストが発生するリスクがあります。このような効率性の問題は特に微妙で、最初の設計は完全に論理的で、合理的なベストプラクティスに従っていたかもしれませんが、後方互換性のある変更を重ねた結果、より効率的な新しい選択肢が重要になってくるのです。ミスはなかったが、時間の経過によって変化が重要になる。

先ほど述べたような懸念があるからこそ、持続可能性に投資していない長期プロジェクトには大きなリスクがあるのです。私たちは、このような問題に対応し、このような機会を利用する能力を持たなければなりません。それが、私たちに直接影響を与えるか、あるいは私たちが構築した技術の推移的な閉鎖だけに現れるかにかかわらず。変化は本質的に良いものではありません。変化のために変化するべきではありません。しかし、私たちには変化する能力が必要です。その必要性を認めるならば、その能力を安価にするための投資をするかどうかも検討すべきです。システム管理者なら誰でも知っているように、テープからリカバリーできることを理論的に知っていることと、実際にどうやってリカバリーするのか、必要になったときにどれくらいのコストがかかるのかを正確に知っていることは別物です。実践と専門知識は、効率と信頼性の大きな原動力となる。

## 規模と効率

Site Reliability Engineering (SRE)の本にも書かれているように(*11)、Googleの生産システムは全体として、人類が生み出した最も複雑な機械の一つです。このような機械を構築し、それを円滑に稼働させるためには、組織内や世界中の専門家が数え切れないほどの時間をかけて考え、議論し、再設計しなければならないという複雑さがあります。ですから、私たちはすでに、そのマシンをあの規模で動かし続けることの複雑さについて、本を書いています。

この本の多くは、そのようなマシンを生み出す組織のスケールの複雑さと、そのマシンを長期間稼働させ続けるために使用するプロセスに焦点を当てています。ここで、コードベースの持続可能性という概念について考えてみましょう。「組織のコードベースが持続可能なのは、変更すべきものをすべて安全に変更することができ、コードベースの寿命が尽きるまでそうすることができるときです。」 能力の議論の中には、コストの議論も含まれています。何かを変更するのに莫大なコストがかかる場合、それはおそらく延期されるでしょう。時間の経過とともにコストが超直線的に増加するようであれば、そのオペレーションは明らかにスケーラブルではありません(*12)。最終的には、時間の経過とともに、どうしても変更しなければならない予期せぬことが発生します。プロジェクトの規模が2倍になって、もう一度その作業をしなければならなくなったとき、手間が2倍になるでしょうか。また、その問題に対処するために必要な人的資源もあるでしょうか？

スケーリングが必要な有限のリソースは人的コストだけではありません。ソフトウェア自体が、計算機、メモリ、ストレージ、帯域幅などの従来のリソースをうまく利用して拡張する必要があるのと同様に、ソフトウェアの開発も、人間の時間的関与と開発ワークフローを動かす計算機リソースの両方の観点から、拡張する必要があります。もし、テストクラスタの計算コストが超直線的に増加し、四半期ごとに一人当たりの計算リソースの消費量が増えるようであれば、持続不可能な道を歩んでおり、早急に変更する必要があります。

最後に、ソフトウェア組織の最も貴重な資産であるコードベース自体も拡張する必要があります。ビルドシステムやバージョン管理システムが、成長や変更履歴の増加の結果、時間の経過とともに超線形的にスケールアップしている場合は、単純に進められないポイントが来るかもしれません。フルビルドにはどれくらいの時間がかかるか」「リポジトリの新しいコピーを取得するにはどれくらいの時間がかかるか」「新しい言語バージョンにアップグレードするにはどれくらいの費用がかかるか」など、多くの質問は積極的に監視されておらず、ゆっくりとしたペースで変化していきます。問題がゆっくりと悪化していき、一過性の危機として顕在化することがないため、ゆでガエルのようになってしまうのです。組織全体がスケーリングを意識して取り組まなければ、これらの問題を把握することはできません。

コードの生成と保守のために組織が利用しているすべてのものは、全体的なコストとリソースの消費の観点から、スケーラブルであるべきです。特に、組織が繰り返し行わなければならないことは、人間の労力の点でスケーラブルでなければなりません。一般的なポリシーの多くは、この意味でスケーラブルではないようです。

## スケールしないポリシー

少し練習すれば、スケーリング特性に問題のあるポリシーを簡単に見つけることができるようになります。最も一般的な方法は、一人のエンジニアに課せられた仕事を考慮し、組織が10倍、100倍にスケールアップすることを想像することで、これらを特定することができます。10倍になったら、サンプルのエンジニアが追いつかなければならない仕事が10倍になるのか？組織の大きさに応じて、エンジニアがこなさなければならない仕事の量は増えていくのでしょうか？コードベースの大きさに応じて、仕事の規模も大きくなるのでしょうか？これらのいずれかに当てはまる場合、その作業を自動化または最適化するための仕組みがありますか？もしそうでなければ、スケーリングの問題があります。

廃止措置に対する伝統的なアプローチを考えてみましょう。非推奨については第15章で詳しく説明しますが、一般的な非推奨のアプローチは、スケーリングの問題を示す良い例となります。新しいWidgetが開発されました。みんなが新しいものを使い、古いものを使うのをやめるべきだという決定がなされました。この動機付けのために、プロジェクト・リーダーは「8月15日に古いウィジットを削除しますので、必ず新しいウィジットに移行してください」と言う。

このようなアプローチは、小規模なソフトウェア環境では有効かもしれませんが、依存関係のグラフの深さと幅の両方が大きくなると、すぐに失敗してしまいます。チームはますます多くのウィジットに依存しており、1つのビルドの不具合が会社の大部分に影響を及ぼす可能性があります。このような問題をスケーラブルに解決するには、廃止措置の方法を変える必要があります。移行作業をお客様に押し付けるのではなく、チームが自分たちで内製化することで、規模の経済性を高めることができます。

2012年、私たちはこの問題に歯止めをかけようと、Churn（解約）を緩和するルールを導入しました。インフラチームは、社内のユーザーを新しいバージョンに移行させる作業を自分たちで行うか、後方互換性のある方法でアップデートを行う必要があります。私たちはこのポリシーを「チャーン・ルール」と呼んでいますが、これにより、依存するプロジェクトが追いつくために次第に大きな労力を費やすことがなくなり、スケールアップが可能になりました。また、すべてのユーザーにメンテナンスの労力を求めるよりも、専任のエキスパートグループに変更を実行させた方が、スケールが大きくなることも分かりました。エキスパートは、問題全体を深く学ぶために時間を費やし、その専門知識をすべてのサブプロブレムに適用します。ユーザーに解約への対応を強いることは、影響を受けたすべてのチームの立ち上がりが悪くなり、当面の問題を解決した後、役に立たない知識を捨ててしまうことになります。専門知識の拡張性が高い。

従来の開発ブランチの使用は、スケーリングの問題を含んだポリシーの例です。ある組織は、大規模な機能をトランクにマージすることで製品が不安定になっていることを認識し、「マージするタイミングをより厳しく管理する必要がある。マージの頻度を減らすべきだ」と結論づけたとします。そうすると、すべてのチームやすべての機能が別々の開発ブランチを持つことになります。あるブランチが「完成」したと判断されると、そのブランチはテストされてトランクにマージされますが、その際、その開発ブランチで作業を続けている他のエンジニアは、再同期やテストという形で、コストのかかる作業を行うことになります。このようなブランチ管理は、5～10個のブランチを管理している小規模な組織であれば、うまくいくでしょう。しかし、組織の規模（およびブランチの数）が大きくなると、同じ作業をするために支払うオーバーヘッドがどんどん増えていくことがすぐにわかります。規模が大きくなると、別のアプローチが必要になりますが、それについては第16章で説明します。

## 規模に応じたポリシー

どのような種類のポリシーが、組織の成長に伴ってより良いコストをもたらすのか？もっと言えば、組織の成長に合わせて超線形の価値を提供するためには、どのような種類のポリシーを導入すればよいのでしょうか？

私たちのお気に入りの社内ポリシーの1つは、インフラチームが安全にインフラの変更を行うことができるように保護する、インフラチームのための素晴らしいものです。「インフラを変更した結果、製品に障害などの問題が発生しても、継続的インテグレーション（CI）システムのテストで問題が表面化しなかった場合は、インフラの変更のせいではありません。」もっと口語的に言うと、これは「気に入ったのなら、CIテストを入れるべきだった」という言い回しで、私たちはこれを「ビヨンセ・ルール」と呼んでいます(*13)。スケーリングの観点から見ると、ビヨンセ・ルールは、共通のCIシステムで起動されない複雑で一回限りの特注テストはカウントしないということを意味しています。これがないと、インフラチームのエンジニアは、影響を受けるコードを持つすべてのチームを追跡して、テストの実行方法を尋ねなければならないことも考えられます。エンジニアの数が100人だった頃はそれができました。しかし、もうそんな余裕はありません。

私たちは、組織の規模が大きくなるにつれて、専門知識と共有コミュニケーションフォーラムが大きな価値を持つことを発見しました。エンジニアが共有フォーラムで議論したり、質問に答えたりすることで、知識が広がっていきます。新しい専門家も増えていきます。100人のエンジニアがJavaを書いているとしたら、質問に答えてくれるフレンドリーで親切なJavaの専門家が1人いれば、すぐに100人のエンジニアがより良いJavaコードを書くようになります。知識は伝播し、専門家はキャリアとなります。エンジニアの共通の障害を取り除くことには、多くの価値があります。この点については、第3章で詳しく説明します。

## 例 コンパイラのアップグレード

コンパイラをアップグレードするという大変な作業を考えてみましょう。理論的には、言語が後方互換性を保つためにどれほどの努力をしているかを考えると、コンパイラのアップグレードは安いはずですが、実際にはどれほど安い作業なのでしょうか？これまでに一度もアップグレードを行ったことがない場合、自分のコードベースがその変更に対応しているかどうかをどのように評価するのでしょうか？

私たちの経験では、言語やコンパイラのアップグレードは、大まかには後方互換性があると期待されていても、微妙で難しい作業です。コンパイラのアップグレードは、ほとんどの場合、誤コンパイルの修正、最適化の微調整、あるいは以前は定義されていなかったことの結果を変更する可能性など、動作に小さな変更をもたらします。このような潜在的な結果に対して、あなたのコードベース全体の正しさをどのように評価しますか？

Googleの歴史の中で最も有名なコンパイラのアップグレードは、2006年に行われました。その時点で、Googleは設立から数年が経過し、数千人のエンジニアが在籍していました。コンパイラの更新は約5年ぶりでした。ほとんどのエンジニアはコンパイラを変更した経験がありませんでした。ほとんどのコードは、1つのバージョンのコンパイラにしか触れていませんでした。ほとんどがボランティアで構成されたチームにとって、この作業は困難で苦痛を伴うものでした。最終的には、上流のコンパイラや言語の変更を回避するために、ショートカットや簡略化を見つけることになりましたが、どのように採用すればよいかはわかりませんでした(*14)。結局、2006年のコンパイラのアップグレードは非常に苦痛を伴うものでした。大小さまざまなHyrum's Lawの問題がコードベースに忍び込み、特定のコンパイラバージョンへの依存を深めていたのです。そのような暗黙の依存関係を断ち切ることは苦痛でしかありませんでした。まだビヨンセ・ルールもなく、CIシステムも普及していなかったため、変更の影響を事前に把握することも、リグレッションの責任を問われないことを確認することも困難でした。

この話は決して珍しいことではありません。多くの企業のエンジニアが、痛みを伴うアップグレードについて同じような話をすることができます。珍しいのは、その作業が苦痛であったことを事後的に認識し、スケーリングの問題を克服し、スケールを有利にするために、技術と組織の変更に焦点を当て始めたことです。自動化（一人の人間がより多くのことをできるように）、統合/一貫性（低レベルの変更が限られた問題範囲で済むように）、専門知識（数人の人間がより多くのことをできるように）です。

頻繁にインフラを変更すればするほど、その作業は容易になります。ほとんどの場合、コンパイラのアップグレードなどでコードが更新されると、コードがもろくなり、将来的なアップグレードが容易になることがわかっています。ほとんどのコードが何度かのアップグレードを経ているエコシステムでは、コードは根本的な実装のニュアンスに依存しなくなり、代わりに言語やOSが保証する実際の抽象化に依存するようになります。何をアップグレードするかにかかわらず、コードベースの最初のアップグレードは、他の要因を考慮しても、それ以降のアップグレードよりも大幅にコストがかかることが予想されます。

このように、私たちはコードベースの柔軟性に影響を与える多くの要因を発見してきました。

専門知識

いくつかの言語では、多くのプラットフォームで数百ものコンパイラーのアップグレードを行ってきた実績があります。

安定性

定期的にリリースを採用しているため、リリース間の変化が少ない。いくつかの言語では、1～2週間ごとにコンパイラのアップグレードを実施している。

整合性

定期的にアップグレードを行っているため、まだアップグレードされていないコードが少なくなっています。

親しみやすさ

定期的にアップグレードを行っているので、アップグレードのプロセスにおける冗長性を発見し、自動化を図ることができます。これは、SREの労働に対する考え方と大きく重なります(*15)。

ポリシー

私たちは、「ビヨンセ・ルール」のようなプロセスとポリシーを持っています。これらのプロセスの正味の効果は、インフラストラクチャーチームがすべての未知の使用法を心配する必要がなく、CIシステムで目に見えるものだけを心配すればよいため、アップグレードが実現可能であるということです。

根本的な教訓は、コンパイラのアップグレードの頻度や難易度ではなく、コンパイラのアップグレード作業が必要であると認識した時点で、コードベースが成長しても一定数のエンジニアで作業を確実に行う方法を見つけたということです(*16)。もしも、この作業はコストがかかりすぎるので将来的には避けるべきだと判断していたら、10年前のバージョンのコンパイラをまだ使っていたかもしれません。最適化の機会を逃した結果、計算機資源に25％ほど余分に支払っているかもしれません。2006年製のコンパイラでは投機的実行の脆弱性を軽減できないため、中央のインフラは重大なセキュリティリスクにさらされる可能性があります。停滞は選択肢の一つではありますが、多くの場合、賢明な選択肢ではありません。

## Shifting Left

開発者のワークフローの早い段階で問題を発見すれば、通常はコストを削減できるという考え方は、私たちが目にしてきた大いなる真実の一つです。ある機能に関する開発者のワークフローのタイムラインを左から右に向かって考えてみましょう。構想と設計から始まり、実装、レビュー、テスト、コミット、カナリア、そして最終的な本番デプロイまでの流れです。図1-2に示すように、問題の発見をこのタイムラインの早い段階で「左」に移すことで、長く待つよりも安く修正することができます。

この言葉は、セキュリティを開発プロセスの最後まで延期してはならないという主張から生まれたようで、「セキュリティを左にシフトする」という必要な呼びかけがなされています。この場合の議論は比較的単純です。製品が生産された後になってセキュリティ問題が発見された場合、非常に高価な問題を抱えていることになります。本番環境に導入する前に問題を発見した場合、問題を特定して改善するためには多くの作業が必要になるかもしれませんが、費用は安く済みます。最初の開発者がその欠陥をバージョンコントロールにコミットする前に発見できれば、さらに安くなります。彼らはすでにその機能を理解しているので、新たなセキュリティ制約に応じて修正する方が、コミットして他の人にトリアージと修正をさせるよりも安く済みます。

![Fig 1-2](../img/Fig1-2.png)

この本では、同じ基本パターンが何度も出てきます。コミットされる前に静的解析とコードレビューによって検出されたバグは、本番稼動するバグよりもはるかに安上がりです。開発プロセスの初期段階で品質、信頼性、セキュリティを強調するツールやプラクティスを提供することは、多くのインフラチームにとって共通の目標です。ひとつのプロセスやツールが完璧である必要はありません。そのため、徹底した防御のアプローチを想定し、グラフの左側にある欠陥をできるだけ多くキャッチしたいと考えています。

## トレードオフとコスト

プログラムの書き方を理解し、メンテナンスしているソフトウェアの寿命を理解し、新機能の制作やメンテナンスを行うエンジニアの数が増えて規模が大きくなっても、ソフトウェアを維持する方法を理解していれば、あとは正しい判断をするだけです。ソフトウェアエンジニアリングにおいても、人生と同じように、良い選択が良い結果をもたらすというのは、当然のことのように思えます。しかし、この観察結果の影響は見落とされがちです。Googleには、「私が言ったから」という言葉を嫌う人たちがいます。どんなトピックでも決定者がいて、決定が間違っているように見えるときには明確なエスカレーションパスがあることは重要ですが、目標はコンセンサスであって、全会一致ではありません。「あなたの評価基準には同意できないが、あなたがそのような結論を出すのは理解できる」というケースがあっても構いませんし、期待もしています。このように、すべてのことには理由が必要であるという考えが根底にあります。「ただ、だから」「私がそう言ったから」「みんながこうしているから」というのは、誤った判断が潜んでいる場所です。2つのエンジニアリングオプションの一般的なコストを決定する際、効率的な場合はいつでも自分の仕事を説明できるようにすべきです。

コストとは何を意味するのでしょうか？ここではドルの話だけではありません。"コスト "とは、大まかに言えば "努力 "であり、以下のような要素のいずれかまたはすべてを含みます。

- 金銭的コスト（例：お金)
- リソースコスト(例：CPU時間)
- 人件費（例：エンジニアの労力)
- 取引コスト（例：行動を起こすのにかかる費用)
- 機会費用 (例：行動を起こさないことに何の費用がかかるのか？)
- 社会的コスト（例：この選択が社会全体にどのような影響を与えるか？)

歴史的に見て、社会的コストの問題は特に無視されがちでした。しかし、Googleをはじめとする大手テクノロジー企業は、何十億人ものユーザーに信頼される製品を展開できるようになりました。多くの場合、これらの製品は明らかに純利益をもたらしますが、このような規模で運営されている場合、使いやすさ、アクセシビリティ、公平性、悪用の可能性など、わずかな違いでも拡大され、多くの場合、すでに疎外されているグループに不利益をもたらします。ソフトウェアは社会や文化の多くの側面に浸透しているため、製品や技術的な決定を行う際には、自分たちが可能にしている良い点と悪い点の両方を認識することが賢明です。この点については、第4章で詳しく説明します。

前述のコスト（またはその見積もり）に加えて、現状維持バイアス、損失回避などのバイアスがあります。コストを評価する際には、先に挙げたすべてのコストを念頭に置く必要があります。組織の健全性とは、単に銀行にお金があるかどうかだけではなく、メンバーが価値を感じて生産性を上げているかどうかも重要です。ソフトウェアエンジニアリングのように創造性に富み、収益性の高い分野では、通常、金銭的コストは制限要因ではなく、人的コストが制限要因となります。エンジニアが満足し、集中し、働き続けることで得られる効率的な利益は、他の要因を容易に凌駕します。なぜなら、集中力と生産性は非常に変化しやすいものであり、10〜20％の差は容易に想像できるからです。

## 例 マーカー

多くの組織では、ホワイトボード用のマーカーは貴重品として扱われています。厳重に管理され、常に不足しています。いつも、ホワイトボードのマーカーの半分は乾いていて使えません。あなたは、マーカーがないために会議が中断したことがありますか？マーカーが切れたために思考が脱線したことはありませんか？おそらく、他のチームがマーカーを使い果たしてしまい、自分のマーカーを持ち出したために、すべてのマーカーがなくなってしまったことはないだろうか。すべては1ドルにも満たない製品のために。

グーグルでは、ほとんどの仕事場のクローゼットにホワイトボードマーカーを含む事務用品がたくさん置かれています。さまざまな色のマーカーを何十本も、すぐに手に入れることができるのです。誰かが大量のマーカーを持って歩き回らないようにすることよりも、障害のないブレインストーミングに最適化することのほうがはるかに重要なのです。

私たちは、オフィス用品や従業員の福利厚生、開発者の日々の経験、グローバル規模のサービスのプロビジョニングや運営方法など、すべての活動において、コストとベネフィットのトレードオフを同じレベルで見極め、明確に判断することを目指しています。私たちはよく、「Googleはデータドリブンな文化だ」と言います。データがない場合でも、証拠や前例、議論があるかもしれません。エンジニアリングの意思決定を正しく行うには、利用可能なすべてのインプットを考慮し、トレードオフについて十分な情報を得た上で判断することが重要です。時には、直感や一般的なベストプラクティスに基づいて決断を下すこともありますが、それは真の基本的なコストを測定したり見積もったりするアプローチを使い果たした後のことです。

最終的には、エンジニアリンググループでの意思決定は、非常に少ないものになるはずです。

- 我々がこれを行うのは、必要だからである（法的要求、顧客要求）。
- 現在の証拠に基づいて、その時点で考えられる最良の選択肢（適切な決定者によって決定される）であるから、これを行う。

私がそう言ったからこうする」という判断ではいけません(*17)。

## 意思決定のためのインプット

データを計量する際には、2つの共通したシナリオがあります。

- 関係するすべての量が測定可能であるか、少なくとも推定可能である。これは通常、CPUとネットワーク、ドルとRAMの間のトレードオフを評価していることを意味し、データセンター全体でN個のCPUを節約するために、2週間のエンジニア時間を費やすかどうかを検討していることを意味します。
- 量の中には微妙なものもありますし、どうやって測定したらいいのかもわからないものもあります。時には、「どれだけのエンジニアタイムが必要なのかわからない」という形で現れます。設計不良のAPIのエンジニアリングコストをどうやって測定するのか？あるいは、製品の選択が社会に与える影響は？

最初のタイプの決定に失敗する理由はほとんどありません。ソフトウェアエンジニアリングの組織であれば、コンピュートリソース、エンジニアの時間、その他定期的にやり取りする量に対する現在のコストを追跡することができますし、そうすべきです。正確な金額を組織内で公表したくない場合でも、「このCPUのコストは、このRAMやネットワークの帯域幅のコストと同じ」という換算表を作成することができます。

合意された換算表があれば、各エンジニアは自分で分析することができます。「このリンクリストを2週間かけてより高性能な構造に変更すると、5ギガバイトのRAMを使用することになりますが、2,000個のCPUを節約することができます。やるべきでしょうか？」この質問は、RAMとCPUの相対的なコストだけでなく、人件費（ソフトウェアエンジニアの2週間のサポート）や機会費用（そのエンジニアが2週間で他に何を作れるか）にも左右されます。

2つ目のタイプの決定には、簡単な答えはありません。このような問題を解決するためには、経験、リーダーシップ、そして前例に頼ることになります。私たちは、数値化しにくいものを数値化するための研究に投資しています（第7章参照）。しかし、私たちが持っている最も良い大まかな提案は、すべてが測定可能であったり予測可能であったりするわけではないことを認識し、そのような決定を同じ優先順位で、より慎重に扱うよう試みることです。このような決定は、重要性は同じですが、管理が難しいことが多いのです。

## 例 分散ビルド

ビルドについて考えてみましょう。完全に非科学的なTwitterの調査によると、今日の大規模で複雑なビルドであっても、60～70%の開発者がローカルにビルドしているようです。このことは、この「Compiling」コミックに示されているように、冗談ではないことにつながります。あなたの組織では、ビルドを待つためにどれだけの生産的な時間が失われていますか？それを、小規模なグループのためにdistccのようなものを実行するコストと比較してみてください。あるいは、大規模なグループのために小規模なビルドファームを運営するにはどれくらいのコストがかかるでしょうか? これらのコストが純利益となるには、何週間、何ヶ月かかるでしょうか？

2000年代半ば、Googleは純粋にローカルビルドシステムに依存していました。大規模なローカルマシンを持っている場合もありましたが（デスクトップでマップを作成することもできました！）、コードベースが大きくなるにつれ、コンパイルにかかる時間はどんどん長くなっていきました。当然のことながら、ロスタイムによる人件費のオーバーヘッドや、ローカルマシンの大型化・高性能化によるリソースコストの増加などが発生しました。特に問題だったのは、リソースコストです。もちろん、できるだけ早くビルドしてもらいたいのですが、高性能なデスクトップの開発マシンはほとんどの場合、眠ったままになってしまいます。これではせっかくのリソースを適切に活用できないと感じました。

最終的に、Googleは独自の分散型ビルドシステムを開発しました。このシステムの開発には、もちろんコストがかかりました。開発にはエンジニアの時間がかかり、全員の習慣やワークフローを変えて新しいシステムを習得するには、さらにエンジニアの時間が必要で、もちろん計算機資源の追加も必要でした。しかし、全体的なコスト削減効果は明らかに価値のあるものでした。ビルドが速くなり、エンジニアの時間が回収され、ハードウェアへの投資は、これまで以上に強力なデスクトップマシンではなく、管理された共有インフラ（実際にはプロダクションフリートのサブセット）に集中できるようになりました。第18章では、分散ビルドへのアプローチとそのトレードオフについて詳しく説明しています。

新しいシステムを構築し、それを本番環境にデプロイし、全員のビルドを高速化しました。これで物語はハッピーエンドでしょうか？分散ビルドシステムを導入することで、エンジニアの生産性は大幅に向上しましたが、時間が経つにつれて分散ビルド自体が肥大化していきました。以前のケースでは、エンジニア個人の制約（ローカルのビルドをできるだけ速くしたいという利害関係があったため）が、分散ビルドシステムの中では制約がなくなってしまったのです。ビルドグラフが肥大化したり、不必要な依存関係が発生したりすることはよくあることでした。全員が最適ではないビルドの痛みを直接感じ、警戒するインセンティブを得られれば、インセンティブの整合性が高まります。このようなインセンティブを排除し、並列分散ビルドで肥大化した依存関係を隠蔽することで、消費が横行し、ビルドの肥大化に注意を払うインセンティブがほとんどない状況を作り出しました。これは、ジェヴォンズ・パラドックスを彷彿とさせます。ある資源の使用効率が高まると、その資源の消費量が増加するというものです。

全体的に見て、分散型ビルドシステムを追加することで得られるコスト削減効果は、その構築と維持に伴うマイナスのコストをはるかに上回っています。しかし、消費量の増加に見られるように、これらのコストのすべてを予測していたわけではありません。先を急ぐあまり、システムの目標や制約、使用方法を再認識し、ベストプラクティス（小さな依存関係、機械による依存関係の管理）を見極め、新しいエコシステムのためのツールやメンテナンスに資金を投入しなければならない状況に陥ってしまいました。エンジニアの時間を回収するために、コンピュートリソースに何ドルも費やす」というような比較的単純なトレードオフであっても、予期せぬ下流への影響がありました。

## 例 時間とスケールの選択

「時間」と「規模」という大きなテーマは、多くの場合、重なり合って連動しています。ビヨンセ・ルールのようなポリシーは、時間をかけて物事を維持するのに役立ちます。OSのインターフェイスが変更されると、それに対応するために多くの小さなリファクタリングが必要になるかもしれませんが、それらの変更のほとんどは似たような形をしているため、うまくスケールします。

時折、時間と規模が衝突することがありますが、これほど明確なのは、「依存関係を追加すべきか、それともローカルなニーズに合わせてフォーク/再実装すべきか」という基本的な問題です。

この問題は、ソフトウェアスタックの様々なレベルで発生する可能性があります。なぜなら、狭い問題領域に合わせてカスタマイズされた特注のソリューションが、あらゆる可能性に対応する必要のある汎用のソリューションよりも優れていることがよくあるからです。ユーティリティーコードをフォークしたり再実装したりして、自分の狭い領域に合わせてカスタマイズすることで、マイクロサービス、インメモリキャッシュ、圧縮ルーチンなど、ソフトウェアエコシステム内のあらゆるものに関係なく、新機能をより簡単に追加したり、より確実に最適化したりすることができます。さらに重要なのは、このようなフォークによって得られるコントロールは、基本的な依存関係の変更からあなたを隔離することです。時間の経過や変化の必要性に対して、いつ、どのように対応するかをコントロールすることができます。

一方で、すべての開発者が、既存のものを再利用するのではなく、ソフトウェアプロジェクトで使用されているものをすべてフォークしてしまうと、持続可能性とともにスケーラビリティも損なわれてしまいます。基盤となるライブラリのセキュリティ問題への対応は、もはや単一の依存関係とそのユーザーを更新する問題ではなく、その依存関係のすべての脆弱なフォークと、そのフォークのユーザーを特定する問題です。

多くのソフトウェアエンジニアリングの決定と同様に、このような状況には万能な答えはありません。プロジェクトのライフスパンが短ければ、フォークのリスクは低くなります。また、時間やプロジェクトの境界を越えて動作する可能性のあるインターフェース（データ構造、シリアライズフォーマット、ネットワークプロトコル）のフォークは避けた方がいいでしょう。一貫性には大きな価値がありますが、一般性にはそれなりのコストがかかり、慎重に行えば自分のやり方で勝てることも多いのです。


## 決定を見直し、間違いを犯す

データ駆動型の文化に取り組むことの知られざる利点の一つは、間違いを認める能力と必要性を兼ね備えていることです。ある時点で、利用可能なデータに基づいて意思決定が行われます。できれば、優れたデータとわずかな仮定に基づいて行いたいものですが、暗黙のうちに現在利用可能なデータに基づいて行われます。新しいデータが入ってきたり、状況が変化したり、前提条件が崩れたりすると、その決定に誤りがあったことが明らかになったり、当時は意味があったが今は通用しないことがわかったりします。これは、長い歴史を持つ組織にとっては特に重要なことです。時間の経過は、技術的な依存関係やソフトウェアシステムの変化だけでなく、意思決定に使用されるデータの変化も引き起こします。

私たちは、データが意思決定に反映されることを強く信じていますが、データは時間とともに変化し、新しいデータが現れることもあると認識しています。つまり、対象となるシステムの寿命が尽きるまで、意思決定は時々見直さなければならないのです。長期間にわたるプロジェクトでは、最初に決定した後に方向性を変える能力が重要になることがよくあります。そして、重要なことは、決定者が間違いを認める権利を持つことです。人によっては直感的にそう思うかもしれませんが、間違いを認めるリーダーは尊敬されるどころか、尊敬されません。

エビデンスを重視する一方で、測定できないものにも価値があることを認識してください。あなたがリーダーであれば、それがあなたに求められていることです。判断力を働かせ、物事の重要性を主張するのです。リーダーシップについては、第5章と第6章で詳しく説明します。


## ソフトウェアエンジニアリングとプログラミング

ソフトウェアエンジニアリングとプログラミングを区別すると、そこには本質的な価値判断が含まれているのではないかと疑問に思うかもしれません。プログラミングはソフトウェアエンジニアリングよりも悪いのか？何百人ものチームで10年続くと予想されるプロジェクトの方が、2人で作って1ヶ月しか使えないプロジェクトよりも本質的に価値があるのでしょうか？

もちろん、そんなことはありません。私たちが言いたいのは、ソフトウェアエンジニアリングが優れているということではなく、これらは異なる制約、価値、ベストプラクティスを持つ2つの異なる問題領域を表しているということです。むしろ、この違いを指摘することの価値は、あるツールが一方の領域では優れていても、他方の領域ではそうではないことを認識することにあります。例えば、数日しか持たないプロジェクトでは、統合テスト（第14章参照）や継続的なデプロイメント（第24章参照）に頼る必要はないでしょう。同様に、セマンティック・バージョニング（SemVer）やソフトウェア・エンジニアリング・プロジェクトにおける依存関係管理（第21章参照）などの長期的な懸念事項は、短期的なプログラミング・プロジェクトにはあまり当てはまりません。

私たちは、"プログラミング "と "ソフトウェアエンジニアリング "という、関連しつつも異なる用語を区別することが重要だと考えています。その違いの多くは、時間をかけたコードの管理、時間がスケールに与える影響、そしてそれらの考えに直面したときの意思決定に起因しています。プログラミングとは、コードを作成するという直接的な行為です。一方、ソフトウェアエンジニアリングとは、コードを必要なときに必要なだけ使えるようにするために必要なポリシー、プラクティス、ツールのセットであり、チーム間のコラボレーションを可能にするものです。


## 結論

本書では、組織や一人のプログラマーのためのポリシー、ベストプラクティスの評価と改善方法、保守可能なソフトウェアに必要なツールや技術など、これらすべてのトピックについて説明しています。Googleは、持続可能なコードベースと文化を持つために努力してきました。私たちのアプローチが必ずしも唯一の真の方法であるとは考えていませんが、それが可能であることを例を挙げて証明しています。また、一般的な問題を考える上での有用なフレームワークとなることを期待しています。すなわち、「コードが機能し続けるために必要な期間、どのようにしてコードを維持するか」という問題です。

## TL;DRs

- "ソフトウェアエンジニアリング "は、"プログラミング "とは次元が異なります：プログラミングはコードを作成することです。プログラミングとは、コードを作成することであり、ソフトウェアエンジニアリングとは、そのコードを有用な寿命まで維持することを含みます。
- 寿命の短いコードと寿命の長いコードの寿命には、少なくとも10万倍の差があります。その両端に同じベストプラクティスが普遍的に適用されると考えるのは愚かなことです。
- ソフトウェアが持続可能であるとは、コードの予想寿命の間、依存関係、技術、製品要求の変化に対応できることを意味します。変更しないことを選択することもできますが、対応できる能力が必要なのです。
- Hyrum's Law: 十分な数のAPIユーザーがいれば、契約で何を約束するかは重要ではありません：あなたのシステムの観察可能なすべての動作は、誰かに依存します。
- 組織が繰り返し行わなければならないすべてのタスクは、人間の入力に関してスケーラブル（線形またはそれ以上）でなければならない。ポリシーは、プロセスをスケーラブルにするための素晴らしいツールです。
- プロセスの非効率性やその他のソフトウェア開発のタスクは、ゆっくりとスケールアップする傾向があります。ゆでガエルのような問題には注意が必要です。
- 専門知識は、規模の経済と組み合わされたときに、特に効果を発揮します。
- 「私がそう言ったから」というのは、物事を行う上での最悪の理由です。
- データを重視することは良いスタートですが、実際には、ほとんどの決定は、データ、仮定、前例、議論の組み合わせに基づいて行われます。客観的なデータがそれらのインプットの大半を占めるのがベストですが、すべてを占めることはほとんどありません。
- 時間をかけてデータドリブンであるということは、データが変化したとき（あるいは前提が崩れたとき）には方向性を変える必要があるということです。間違いや計画の修正は避けられません。

-----

1 「実行寿命」ではなく、「メンテナンス寿命」という意味です。 このコードはいつまでビルド、実行、メンテナンスされ続けるのか？このソフトウェアはいつまで価値を提供できるのか？
2 技術的負債とは、「やるべきこと」なのに「まだやっていないこと」、つまり「自分のコード」と「こうあってほしいコード」の差分のことであり、手垢のついた定義としては妥当なものでしょう。
3 また、あるプロジェクトが長期に渡ることを事前に知っているかどうかという問題も考えてみましょう。
4 この言葉のオリジナルの帰属については疑問があります。ブライアン・ランデルかマーガレット・ハミルトンが最初に言った言葉だというのがコンセンサスのようですが、デイブ・パーナスが完全に作ったものかもしれません。一般的な引用文は「Software Engineering Techniques」である。Report of a conference sponsored by the NATO Science Committee," Rome, Italy, 27-31 Oct.1969, Brussels, Scientific Affairs Division, NATO.
5 Frederick P. Brooks Jr.The Mythical Man-Month: Essays on Software Engineering (Boston: Addison-Wesley, 1995).
6 Appcelerator, "Nothing is Certain Except Death, Taxes and a Short Mobile App Lifespan," Axway Developer blog, December 6, 2012.
8 Hyrumはこれを「The Law of Implicit Dependencies（暗黙の依存性の法則）」と謙虚に呼ぼうと努力しましたが、Googleでは「Hyrum's Law」がほとんどの人の間で定着しています。
9 xkcdのコミック「Workflow」を参照。
10 サービス拒否（DoS）攻撃の一種で、信頼されていないユーザーがハッシュテーブルの構造やハッシュ関数を知り、テーブル上での演算のアルゴリズム性能を低下させるような方法でデータを提供する攻撃のこと。
11 Beyer, B. et al. Site Reliability Engineering: How Google Runs Production Systems. (Boston: O'Reilly Media, 2016)を参照してください。
12 本章で非公式な文脈で "スケーラブル "を使用する場合は、常に "人間のインタラクションに関するサブライアン・スケーリング "を意味します。
13 これは、"If you liked it then you shoulda put a ring on it "というリフレインを含む人気曲「Single Ladies」にちなんだものです。
14 具体的には、C++標準ライブラリのインターフェースを名前空間stdで参照する必要があり、std::stringの最適化の変更が、我々の使用方法では大幅なペシミレーションであることが判明したため、いくつかの追加の回避策が必要となりました。
15 Beyer et al. Site Reliability Engineering: How Google Runs Production Systems, Chapter 5, "Eliminating Toil".
16 私たちの経験では、平均的なソフトウェアエンジニア（SWE）は、単位時間あたりにほぼ一定の数のコード行を生成します。SWEの数が一定であれば、コードベースは時間の経過とともにSWEの数に比例して直線的に成長します。コードの行数に比例した労力を必要とするタスクがあるとしたら、それは問題です。
最終的には誰かが決定権を持つ必要があります。最終的には誰かが決定権を持つ必要があります。これは主に、決定に実際に責任を持つ人のために、意思決定プロセスがどのように流れるべきかを示しています。

