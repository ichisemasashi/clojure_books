# CHAPTER 11  Testing Overview

Written by Adam Bender

Edited by Tom Manshreck

テストは、常にプログラミングの一部です。実際、あなたが初めてコンピュータ・プログラムを書いたとき、ほとんどの場合、サンプル・データを投げて、期待通りに動作するかどうかを確認したはずです。長い間、ソフトウェアテストの現状は、主に手作業でエラーを起こしやすい、よく似たプロセスになっていた。しかし、2000年代初頭以降、ソフトウェア業界のテストに対するアプローチは、現代のソフトウェアシステムの規模と複雑さに対応するために劇的に進化した。その進化の中心となったのが、開発者主導の自動テストの実践です。

自動化されたテストを行うことで、バグが外に出てユーザーに影響を与えることを防ぐことができます。開発サイクルの後半にバグを発見すればするほど、そのコストは指数関数的に増加します(*1)。 しかし、「バグを発見すること」は動機の一部に過ぎません。ソフトウェアをテストする理由としては、変化に対応する能力をサポートすることも同様に重要です。新しい機能を追加する場合でも、コードの健全性を重視したリファクタリングを行う場合でも、あるいは大規模な再設計を行う場合でも、自動化されたテストはミスを素早く発見することができるので、安心してソフトウェアを変更することができます。

より速く反復できる企業は、技術や市場の状況、顧客の好みの変化に、より迅速に対応することができます。しっかりとしたテストを実施していれば、変化を恐れる必要はありません。ソフトウェア開発に不可欠な品質として、変化を受け入れることができます。システムをより多く、より速く変更したいと思えば思うほど、迅速なテスト方法が必要になります。

テストを書くという行為は、システムの設計を改善することにもなります。コードの最初のクライアントであるテストは、あなたの設計の選択について多くのことを教えてくれます。あなたのシステムは、データベースと緊密に結合しすぎていませんか？APIは必要なユースケースをサポートしているか？システムはすべてのエッジケースに対応しているか？自動化されたテストを書くことで、開発サイクルの早い段階でこれらの問題に直面することになります。そうすることで、よりモジュール化されたソフトウェアとなり、後々の柔軟性を高めることができるのです。

ソフトウェアのテストについては、これまでも多くの議論がなされてきましたが、それには十分な理由があります。Googleでは、長い道のりを歩んできましたが、会社全体でプロセスを確実にスケールアップさせるという難しい問題に直面しています。本章では、この問題を解決するために、私たちが学んだことを紹介します。


## なぜテストを書くのか？

テストを最大限に活用する方法をよりよく理解するために、最初から始めましょう。自動化されたテストといっても、実際には何のことを言っているのでしょうか？
最もシンプルなテストは次のように定義されます。

- テストしたい単一の動作、通常は呼び出しているメソッドやAPI
- 特定の入力、つまりAPIに渡す何らかの値
- 観測可能な出力または動作
- 隔離された単一のプロセスのような制御された環境

このようなテストを実行して、システムに入力を渡し、出力を検証すると、システムが期待通りに動作するかどうかを知ることができます。数百から数千の単純なテスト（通常、テストスイートと呼ばれます）を総合すると、製品全体が意図した設計にどれだけ適合しているか、さらに重要なことに、どのような場合に適合しないかを知ることができます。

健全なテストスイートを作成し、維持するには大変な努力が必要です。コードベースが成長すると、テストスイートも成長します。不安定さや遅さなどの問題に直面するようになります。これらの問題に対処できなければ、テストスイートは機能しなくなります。テストの価値は、エンジニアの信頼から生まれることを覚えておいてください。もしテストが生産性の低下を招き、常に苦労と不確実性を伴うものになってしまったら、エンジニアは信頼を失い、回避策を見つけ始めます。悪いテスト・スイートは、テスト・スイートが全くないよりも悪いかもしれません。

テストは、企業が優れた製品を迅速に構築するために役立つだけでなく、私たちの生活の中で重要な製品やサービスの安全性を確保するためにも重要な役割を果たしています。ソフトウェアはこれまで以上に私たちの生活に密着しており、不具合が発生すると、単なるトラブルにとどまらず、莫大な費用や財産の損失、最悪の場合は人命の損失につながることもあります(*2)。

Googleでは、テストを後回しにしてはいけないと考えています。品質とテストに重点を置くことは、私たちの仕事のやり方の一部です。私たちは、製品やサービスに品質を組み込むことができなければ、必然的に悪い結果を招くことを、時には痛感してきました。その結果、私たちはエンジニアリング文化の中心にテストを組み込んだのです。

### Google ウェブサーバーの物語

Googleの初期には、エンジニア主導のテストはあまり重要ではないと思われていました。チームは、ソフトウェアを正しく動作させるために、常に頭の良い人たちに頼っていました。いくつかのシステムでは大規模な統合テストが行われていましたが、ほとんどはワイルドウェストのような状態でした。その中でも特に問題となっていたのが、「Google Web Server」（通称GWS）という製品でした。

GWSは、Google検索のクエリを提供するWebサーバーで、Google検索にとっては、空港の航空管制のように重要な役割を果たしています。2005年当時、プロジェクトの規模と複雑さが増すにつれ、生産性は劇的に低下していました。リリースにはバグが多く、リリースまでに時間がかかるようになっていました。チームメンバーは、サービスに変更を加えることに自信が持てず、本番で機能が動作しなくなって初めて何か問題があることに気づくことが多かったのです。(ある時は、本番リリースの80％以上にユーザーに影響を与えるバグが含まれており、ロールバックしなければならなかったこともありました。)

これらの問題に対処するため、GWSの技術リーダー（TL）は、エンジニア主導の自動テストという方針を打ち出すことにしました。このポリシーの一環として、すべての新しいコード変更にはテストを含めることが要求され、それらのテストは継続的に実行されることになったのです。この方針を打ち出してから1年で、緊急プッシュの数は半分になった。プロジェクトでは、四半期ごとに記録的な数の新規変更が行われていたにもかかわらず、この減少は起こりました。前例のない成長と変化に直面しても、テストはGoogleで最も重要なプロジェクトの一つに新たな生産性と自信をもたらしました。現在、GWSには何万ものテストがあり、ほぼ毎日リリースが行われているが、顧客の目に見える失敗は比較的少ない。

GWSの変化は、Googleのテスト文化の分岐点となりました。社内の他の部署のチームがテストの利点を知り、同様の戦術を採用するようになったのです。

GWSの経験から得られた重要な洞察の一つは、製品の欠陥を避けるためには、プログラマーの能力だけに頼ることはできないということです。それぞれのエンジニアがたまにしかバグを書かなかったとしても、同じプロジェクトで働く人が多くなれば、増え続ける不具合のリストに振り回されることになります。仮に100人のチームがあったとして、そのチームのエンジニアが非常に優秀で、それぞれが月に1回しかバグを書かないとします。このような優秀なエンジニアが集まっても、毎日5つの新しいバグを生み出しているのです。さらに悪いことに、複雑なシステムでは、エンジニアが既知のバグに適応してその周りをコーディングするため、1つのバグを修正すると別のバグが発生することがよくあります。

最高のチームは、メンバーの知恵を結集してチーム全体の利益につなげる方法を見つけ出します。それが、自動テストの役割です。チームのエンジニアがテストを作成すると、そのテストは他のメンバーが利用できる共通リソースのプールに追加されます。チームの誰もがテストを実行できるようになり、問題が検出されれば利益を得ることができます。一方、デバッグを基本とするアプローチでは、バグが発生するたびにエンジニアがデバッガを使って調査するコストがかかります。エンジニアのリソースにかかるコストは天と地ほどの差があり、これがGWSが運命を好転させることができた根本的な理由です。

### 最新の開発スピードに合わせたテスト

ソフトウェアシステムはますます大規模化し、複雑化しています。Googleの典型的なアプリケーションやサービスは、数千から数百万行のコードで構成されています。何百ものライブラリやフレームワークを使用し、信頼性の低いネットワークを介して、数え切れないほど多くの設定で動作するプラットフォームに配信しなければなりません。さらに悪いことに、新しいバージョンが頻繁に、時には1日に何度もユーザーにプッシュされます。これは、年に1〜2回しかアップデートされなかったシュリンクラップドソフトウェアの世界とはかけ離れています。

人間がシステムのすべての動作を手動で検証する能力は、ほとんどのソフトウェアの機能やプラットフォームの爆発的な増加に追いついていません。航空券の検索、映画の上映時間、関連画像、そしてもちろんウェブ検索結果など、Google検索のすべての機能を手動でテストするには何が必要か想像してみてほしい（図11-1参照）。その問題を解決する方法がわかったとしても、その作業量に、Google Searchがサポートしなければならないすべての言語、国、デバイスを掛け合わせなければならないし、アクセシビリティやセキュリティなどのチェックも忘れてはならない。すべての機能を人間が手動で操作することで製品の品質を評価しようとしても、スケールアップすることはできません。テストに関しては、自動化という明確な答えがあります。

![fig11-1](../img/Fig11-1.png)

Figure 11-1. 複雑な2つのGoogle検索結果のスクリーンショット

### Write, Run, React

テストの自動化は、純粋な形では、テストの作成、テストの実行、テストの失敗への対応という3つの活動から成り立っています。自動化されたテストとは、テストしたい大規模なシステムの孤立した部分を呼び出す小さなコードであり、通常は1つの関数やメソッドである。テストコードは、期待される環境を設定し、通常は既知の入力を用いてシステムを呼び出し、その結果を検証します。テストの中には、単一のコードパスを使った非常に小規模なものもあれば、モバイルのオペレーティングシステムやウェブブラウザのように、システム全体を対象とした大規模なものもあります。

例11-1では、フレームワークやテストライブラリを使わずに、Javaで意図的にシンプルなテストを行っています。これはテストスイート全体を記述する方法ではありませんが、 自動化されたテストの核心部分はこの非常にシンプルな例に似ています。

Example 11-1. An example test
```C++
// Verifies a Calculator class can handle negative results.
public void main(String[] args) {
   Calculator calculator = new Calculator();
   int expectedResult = -3;
   int actualResult = calculator.subtract(2, 5); // Given 2, Subtracts 5. 
   assert(expectedResult == actualResult);
}
```

かつてのQAプロセスでは、専任のソフトウェアテスターが部屋にこもってシステムの新バージョンを調査し、可能な限りの動作を確認していましたが、今日では、システムを構築するエンジニアは、自らのコードに対して自動テストを書いて実行するという積極的かつ不可欠な役割を担っています。QAが重要な役割を果たしている企業でも、開発者が書いたテストは一般的です。今日のシステム開発のスピードと規模では、テストの開発をエンジニアリングスタッフ全体で共有するしかありません。

もちろん、テストを書くことと、良いテストを書くことは違います。何万人ものエンジニアが良いテストを書けるようにトレーニングするのは、かなり難しいことです。良いテストを書くために学んだことは、この後の章で説明します。

テストを書くことは、自動テストを行う上での最初のステップに過ぎません。テストを書いた後は、それを実行する必要があります。よくあることです。自動テストの基本は、同じ動作を何度も繰り返すことであり、何か問題が発生したときにのみ人間が注意を払う必要があります。この継続的インテグレーション(CI)とテストについては、第23章で説明します。テストを手動の一連の手順ではなくコードとして表現することで、コードが変更されるたびにテストを実行することができます（1日に何千回も簡単に実行できます）。人間のテスターと違って、機械は疲れたり飽きたりすることがありません。

また、テストをコードで表現することで、さまざまな環境で実行できるようにモジュール化しやすいというメリットもあります。例えば、Gmailの動作をFirefoxでテストする場合、Chromeでテストする場合と同じように、両方の環境設定があれば、手間がかかりません(*3)。また、日本語やドイツ語のユーザーインターフェース(UI)のテストも、英語と同じテストコードで実行できます。

開発中の製品やサービスは、どうしてもテストに失敗することがあります。しかし、テストプロセスの有効性を決めるのは、失敗したテストにどう対処するかです。失敗したテストが積み重なると、それまでの価値が失われてしまうので、絶対に避けなければなりません。失敗したテストを数分以内に修正することを優先するチームは、信頼性を高く保ち、失敗を迅速に切り離すことができ、その結果テストからより多くの価値を引き出すことができます。

要約すると、健全な自動テスト文化は、全員がテストを書く作業を共有することを奨励します。このような文化は、テストが定期的に実行されることを保証します。最後に、そしておそらく最も重要なことは、テストの信頼性を高く保つために、壊れたテストを素早く修正することに重点を置くことです。

### コードテストの利点

強力なテスト文化を持たない組織から来た開発者にとって、生産性や速度を向上させる手段としてテストを書くという考えは、相反するものに見えるかもしれません。結局のところ、テストを書くという行為は、そもそも機能を実装するのと同じくらいの時間がかかることがあります。それどころか、Googleでは、ソフトウェアテストに投資することで、開発者の生産性を向上させるいくつかの重要なメリットがあることを発見しました。

- デバッグ作業の軽減
  - 予想されるように、テストされたコードは、提出された時点での欠陥が少なくなります。重要なのは、コードが存在する間中、欠陥が少ないということです。Googleでは、1つのコードが一生の間に何十回も変更されることが予想されます。他のチームや、自動化されたコードメンテナンスシステムによっても変更されるでしょう。一度書かれたテストは、プロジェクトの存続期間中、コストのかかる欠陥や煩わしいデバッグ作業を防ぎ、継続して利益をもたらします。プロジェクトやプロジェクトの依存関係の変更によってテストが壊れることは、テストインフラストラクチャによって素早く検出され、問題が本番にリリースされる前にロールバックされます。
- 変更に対する信頼性の向上
  - すべてのソフトウェアは変更されます。優れたテストを実施しているチームは、プロジェクトの重要な動作がすべて継続的に検証されているため、自信を持ってプロジェクトの変更を検討し、受け入れることができます。このようなプロジェクトは、リファクタリングを促進します。既存の動作を維持しながらコードをリファクタリングする変更は、（理想的には）既存のテストに変更を加える必要はありません。
- ドキュメントの改善
  - ソフトウェアのドキュメントは信頼性が低いことで知られています。時代遅れの要件やエッジケースの欠落など、ドキュメントとコードとの関係が希薄であることはよくあることです。一度に一つの動作を実行する、明確で焦点を絞ったテストは、実行可能なドキュメントとして機能します。特定のケースでコードが何をするのかを知りたければ、そのケースのテストを見ればいいのです。さらに良いことに、要件が変更され、新しいコードが既存のテストを壊してしまった場合、「ドキュメント」が古くなったという明確な信号を得ることができます。なお、テストが文書として最も効果的に機能するのは、テストを明確かつ簡潔に保つように配慮した場合に限られる。
- よりシンプルなレビュー
  - Googleでは、すべてのコードは、投稿する前に少なくとも1人の他のエンジニアによってレビューされます（詳細は第9章を参照）。コードレビューでは、コードの正しさ、エッジケース、エラー条件を示す徹底したテストが含まれていれば、コードが期待通りに動作するかどうかを確認するために費やす労力は少なくて済みます。コードレビューでは、ケースごとにコードを確認する必要がありますが、レビュー担当者は、ケースごとにテストに合格しているかどうかを確認することができます。
- 考え抜かれた設計
  - 新しいコードのテストを書くことは、コード自体のAPI設計を実施するための実用的な手段です。新しいコードのテストが難しい場合、テスト対象のコードの責任が大きすぎたり、依存関係の管理が難しいことが原因であることが多い。適切に設計されたコードは、モジュール化され、緊密な結合を避け、特定の責任に集中するべきです。設計上の問題を早期に解決することは、後の手直しを少なくすることにつながります。
- 迅速かつ高品質なリリース
  - 健全な自動テストスイートがあれば、チームは自信を持ってアプリケーションの新バージョンをリリースすることができます。Googleの多くのプロジェクトでは、毎日新バージョンを本番環境にリリースしています。それは、何百人ものエンジニアがいて、何千ものコード変更が毎日提出されるような大規模なプロジェクトでも同じです。自動化されたテストがなければ、このようなことはできません。

## テストスイートの設計

今日、Google は大規模な事業を展開していますが、昔からそれほど大規模だったわけではなく、私たちのアプローチの基礎はずっと前に築かれました。長年にわたり、コードベースが成長するにつれ、テストスイートの設計と実行のアプローチについて多くのことを学んできました。

かなり早い段階で学んだことの1つは、エンジニアはシステム規模の大きなテストを書くことを好むが、これらのテストは小規模なテストに比べて時間がかかり、信頼性が低く、デバッグが困難であるということでした。システム規模のテストのデバッグにうんざりしたエンジニアたちは、「なぜ一度に1つのサーバーをテストできないのか」「なぜ一度にサーバー全体をテストする必要があるのか」と自問しました。もっと小さなモジュールを個別にテストすればいいのではないか」。最終的には、苦痛を減らしたいという思いから、チームはどんどん小さなテストを開発するようになり、結果的に、より速く、より安定した、そして一般的に苦痛の少ないテストになりました。

これをきっかけに、"small"の正確な意味について、社内では様々な議論がなされました。小さいとはユニットテストのことか？統合テストはどのくらいの規模なのか？私たちは、すべてのテストケースには「サイズ」と「スコープ」という2つの異なる次元があるという結論に達しました。サイズとは、テストケースを実行するのに必要なリソースのことで、メモリ、プロセス、時間などのことです。スコープとは、検証する特定のコードパスのことです。コードを実行することと、そのコードが期待通りに動作することを検証することは異なります。サイズとスコープは相互に関連していますが、異なる概念です。

### テストのサイズ

Google では、すべてのテストをサイズ別に分類し、与えられた機能に対して可能な限り小さなテストを書くようエンジニアに奨励しています。テストのサイズは、コードの行数ではなく、どのように実行されるか、何ができるか、どれだけのリソースを消費するかによって決まります。実際、私たちが定義する小、中、大は、テストインフラがテストに課すことのできる制約として、実際にコード化されているケースがあります。詳細については後ほど説明しますが、簡単に言うと、図11-2に示すように、小テストは単一のプロセスで実行され、中テストは単一のマシンで実行され、大テストは好きな場所で実行されます(*4)。

![fig11-2](../img/Fig11-2.png)

Figure 11-2. テストサイズ

従来の「ユニット」や「インテグレーション」とは異なり、このような区別をしているのは、テストの範囲に関わらず、テストスイートに求められる最も重要な品質が速度と決定性であるためです。小さなテストは、その範囲に関わらず、より多くのインフラを使用したり、より多くのリソースを消費したりするテストよりも、ほとんどの場合、より速く、より決定性の高いものです。小規模なテストに制限を設けることで、速度と決定性をより簡単に実現することができます。テストの規模が大きくなると、多くの制限が緩和されます。中規模のテストでは、より柔軟性がありますが、非決定性のリスクも高くなります。大規模なテストは、最も複雑で困難なテストシナリオのためだけに保存されます。それでは、それぞれのテストタイプに課せられた制約を詳しく見ていきましょう。

#### 小型テスト

小規模テストは、3つのテストサイズの中で最も制約の多いテストです。主な制約は、小規模なテストは単一のプロセスで実行されなければならないということです。多くの言語では、これをさらに制限して、単一のスレッド上で実行しなければならないとしています。つまり、テストを実行するコードは、テストされるコードと同じプロセスで実行されなければならないのです。サーバーを起動して、別のテストプロセスがそれに接続することはできません。また、データベースのようなサードパーティのプログラムをテストの一部として実行することもできません。

その他の重要な制約として、小型テストでは、スリープやI/O操作(*5)、その他のブロッキングコールを行うことができません。つまり、スモールテストは、ネットワークやディスクにアクセスすることができないのです。このような操作に依存しているコードをテストするには、テストダブルス（第13章参照）を使用して、ヘビーウェイトな依存関係を軽量なプロセス内の依存関係に置き換える必要があります。

これらの制限の目的は、小規模なテストが、テストの速度低下や不確定性の主な原因にアクセスできないようにすることです。単一のプロセス上で実行され、ブロック化された呼び出しを行わないテストは、事実上、CPUが処理できる限り高速に実行することができます。このようなテストを誤って遅くしたり、非決定性にしたりすることは困難です（不可能ではありませんが）。小さなテストに対する制約は、エンジニアが自分で自分を撃つことを防ぐためのサンドボックスになります。

これらの制約は、最初は過剰に思えるかもしれませんが、数百個の小さなテストケースからなるささやかなスイートを1日中実行することを考えてみてください。そのうちの数個でも非決定論的に失敗すると（しばしばフレーキーテストと呼ばれる）、その原因を追究することは生産性を著しく低下させます。Googleの規模では、このような問題が発生すると、テストインフラが停止してしまいます。

Googleでは、テストの範囲にかかわらず、可能な限り小さなテストを書くようエンジニアに奨励しています。これは、テストスイート全体を高速かつ確実に実行するためです。スモールテストとユニットテストの比較については、第12章を参照してください。

#### 中規模テスト

小規模なテストに課せられた制約は、多くの興味深い種類のテストにとってあまりにも制限的です。テストのサイズの次の段階は、中規模テストです。中規模テストでは、複数のプロセスにまたがったり、スレッドを使用したり、localhost に対してネットワークコールを含むブロックコールを行うことができます。唯一の制限は、中規模テストでは localhost 以外のシステムにネットワークコールを行うことができないということです。言い換えれば、テストは1台のマシンの中で行わなければなりません。

複数のプロセスを実行できるようになったことで、さまざまな可能性が広がりました。例えば、データベースインスタンスを実行して、テストしているコードが正しく統合されているかどうかを、より現実的な環境で検証することができます。また、Web UIとサーバーコードの組み合わせをテストすることもできます。Webアプリケーションのテストでは、WebDriverのようなツールを使って実際のブラウザを起動し、テストプロセスを介してリモートで制御することがよくあります。

残念ながら、柔軟性が高まると、テストが遅くなったり、非決定論的になったりする可能性が高まります。プロセスをまたいだり、ブロックコールを許可されているテストは、OSやサードパーティのプロセスに高速性や決定性を依存しており、一般的に保証できるものではありません。中程度のテストであれば、ネットワーク経由でのリモートマシンへのアクセスを防ぐことで、多少の保護はできます。ネットワークは、ほとんどのシステムで遅さや非決定性の最大の原因となっています。しかし、中程度のテストを書くときには、「安全性」は失われており、エンジニアはより慎重になる必要があります。

#### 大型テスト

最後に、大規模テストについて説明します。大規模テストでは、中規模テストで課されていたローカルホストの制限がなくなり、テストとテスト対象のシステムが複数のマシンにまたがることができます。例えば、リモート クラスタ内のシステムに対してテストを実行することができます。

前述の通り、柔軟性の向上はリスクの増加を伴います。複数のマシンとそれらをつなぐネットワークにまたがるシステムを扱わなければならないため、単一のマシン上で実行する場合に比べて、速度低下や不確定性が発生する可能性が大きくなります。大規模なテストは、コードよりも構成を検証することに重点を置いたフルシステムのエンドツーエンドのテストや、テストダブルが使用できないレガシーコンポーネントのテストなどに使用します。大規模テストの使用例については、第14章で詳しく説明します。Google のチームでは、大規模なテストを小規模なテストや中規模なテストから分離し、 開発者のワークフローに影響を与えないようにするために、 ビルドやリリースのプロセスでのみ実行することがよくあります。

----

### ケーススタディ フレークテストはコストがかかる

もし数千ものテストがあって、それぞれがほんの少しの非決定性を持っていて、 それを一日中走らせていたら、たまには失敗することもあるでしょう (フレーク)。テストの数が増えれば、統計的にフレークの数も増えます。もし各テストが0.1%でも失敗する可能性があり、1日に10,000個のテストを実行した場合、1日に10個のフレークを調査することになります。それぞれの調査は、あなたのチームができるもっと生産的なことから時間を奪います。

場合によっては、テストが失敗したときに自動的に再実行することで、不具合のあるテストの影響を抑えることができます。これは事実上、CPU サイクルとエンジニアリングの時間を交換することになります。不具合のレベルが低い場合、このトレードオフは理にかなっています。ただし、テストの再実行は、不具合の根本的な原因に対処する必要性を先延ばしにしているだけであることに留意してください。

テストのフレークが増え続けると、生産性の低下よりもはるかに悪いことが起こります。それは、テストに対する信頼の喪失です。チームがテスト・スイートに対する信頼を失うまでには、多くのフレークを調査する必要はありません。そうなると、エンジニアはテストの失敗に反応しなくなり、テスト・スイートが提供していた価値がなくなってしまいます。私たちの経験では、フレーク率が1％に近づくと、テストの価値が失われ始める。Googleでは、フレーク率は0.15%前後で推移しており、これは毎日何千ものフレークが発生していることを意味しています。Googleでは、フレークの発生を抑えるために、エンジニアが積極的にフレークの修正に時間を割くなどの努力をしています。

ほとんどの場合、フレークはテスト自体の非決定論的な動作が原因で発生します。ソフトウェアには、クロックタイム、スレッドスケジューリング、ネットワークレイテンシーなど、多くの非決定性の原因があります。ランダム性の影響を分離し、安定化させる方法を学ぶことは容易ではありません。時には、ハードウェアの割り込みやブラウザのレンダリングエンジンなど、低レベルの問題に結びつくこともあります。優れた自動テストインフラは、エンジニアが非決定論的な動作を特定し、それを軽減するのに役立つはずです。

----

#### すべてのテストサイズに共通する特性

すべてのテストは密閉型であるように努めなければなりません。テストには、その環境をセットアップし、実行し、破壊するために必要なすべての情報が含まれていなければなりません。テストは、テストを実行する順番など、 外部環境についてできる限り想定しないようにしなければなりません。例えば、テストは共有データベースに依存すべきではありません。この制約は、大規模なテストになるほど難しくなりますが、それでも隔離性を確保するための努力は必要です。

テストには、問題となっている動作を実行するのに必要な情報だけを含めるべきです。テストを明確かつシンプルにすることで、コードがその通りに動作するかどうかを確認することができます。また、明確なコードは、失敗したときの診断にも役立ちます。私たちは、"テストは一目瞭然でなければならない "と言っています。テスト自体にはテストがないので、正しさを確認するためには手動でのレビューが必要になります。これに付随して、私たちはテストに条件分岐やループなどの制御フロー文を使用することも強く推奨しません。テストの流れが複雑になると、それ自体にバグが含まれる危険性がありますし、 テストの失敗の原因を突き止めるのが難しくなります。

テストが見直されるのは、何かが壊れたときだけであることを忘れないでください。今まで見たこともないような壊れたテストを修正するように言われたとき、誰かが時間をかけて理解しやすくしてくれたことに感謝するでしょう。コードは書かれるよりも読まれることの方がはるかに多いのですから、自分が読まれたいと思うテストを書くようにしましょう。

**テストサイズの実際**
テストサイズを正確に定義することで、それを実施するためのツールを作成することができました。これにより、テストスイートを拡張しても、速度、リソース使用率、安定性について一定の保証を行うことができるようになりました。Googleでは、これらの定義をどの程度実施しているかは、言語によって異なります。例えば、Google ではすべての Java テストを独自のセキュリティ マネージャを使用して実行しています。このセキュリティ マネージャは、ネットワーク接続の確立などの禁止事項を実行しようとした場合、小さいとタグ付けされたすべてのテストを失敗させます。

### テストスコープ

Googleではテストサイズを重視していますが、もう一つの重要な特性としてテストスコープを考慮する必要があります。テストスコープとは、あるテストでどれだけのコードが検証されているかということです。狭い範囲のテスト (一般に「ユニットテスト」と呼ばれます) は、個々のクラスやメソッドのような、コードベースの小さな集中した部分のロジックを検証するように設計されています。中規模テスト (一般に統合テストと呼ばれる) は、少数のコンポーネント間の相互作用を検証するために設計されています。大規模なテスト (機能テスト、エンドツーエンドテスト、システムテストなどの名称で呼ばれる) は、システムのいくつかの異なる部分の相互作用や、単一のクラスやメソッドでは表現されない出現する動作を検証するように設計されています。

注意すべき点は、ユニットテストのスコープが狭いということは、実行されるコードではなく、検証されるコードに言及しているということです。あるクラスが多くの依存関係を持っていたり、他のクラスを参照していたりすることはよくあることで、これらの依存関係は対象となるクラスのテスト中に自然に呼び出されます。他のテスト戦略では、テスト対象のシステムの外にあるコードの実行を避けるために、テストの替え玉（フェイクやモック）を多用するものもありますが、Google では、実行可能な場合は実際の依存関係を維持することを推奨しています。第13章では、この問題についてさらに詳しく説明します。

狭い範囲のテストは小さく、広い範囲のテストは中規模または大規模になる傾向がありますが、これは必ずしもそうではありません。たとえば、サーバーのエンドポイントに対して 広範な範囲のテストを書くことは可能です。 このテストでは、通常の構文解析やリクエストの検証、 ビジネスロジックをすべてカバーしていますが、 データベースやファイルシステムなどのプロセス外の依存関係を すべてダブルスで代用しているため、規模は小さくなります。同様に、中規模でなければならない単一のメソッドに対して、狭い範囲のテストを書くことも可能です。たとえば、最近のウェブフレームワークでは HTML と JavaScript が一緒になっていることが多く、日付選択ツールのような UI コンポーネントのテストでは、単一のコードパスを検証するためにもブラウザ全体を実行しなければならないことがよくあります。

Googleでは、小さいサイズのテストを推奨しているように、エンジニアにも狭い範囲のテストを書くことを推奨しています。大まかな目安としては、ビジネスロジックの大部分を検証する範囲の狭いユニットテストが80％、2つ以上のコンポーネント間のやり取りを検証する範囲の広い統合テストが15％、そしてシステム全体を検証するエンドツーエンドのテストが5％という構成にしています。図11-3は、これをピラミッド型にしたものです。

![fig11-3](../img/Fig11-3.png)

Figure 11-3. Mike Cohn氏のテストピラミッドのGoogle版。(*6) パーセンテージはテストケース数で、チームごとに構成は少しずつ異なる。


ユニットテストは、高速で安定しており、クラスや関数が持つ可能性のあるすべての動作を特定するために必要な範囲を劇的に狭め、認知的な負荷を減らすことができるため、優れた基盤となります。さらに、ユニットテストは失敗の診断を迅速かつ無痛で行うことができます。注意すべき2つのアンチパターンは、図11-4に示すように、「アイスクリーム・コーン」と「砂時計」です。

アイスクリームコーンの場合、エンジニアはエンドツーエンドのテストをたくさん書きますが、統合テストやユニットテストはほとんど書きません。このようなスイートは、時間がかかり、信頼性が低く、作業がしにくい傾向があります。このパターンは、プロトタイプとしてスタートし、すぐに製品化を急ぐプロジェクトでよく見られ、テストの負債に対処するために停止することはありません。

砂時計は、多くのエンドツーエンドのテストと多くのユニットテストを含みますが、統合テストはほとんどありません。アイスクリームコーンほどひどくはありませんが、それでもエンド・ツー・エンドのテストで多くの失敗が発生し、中規模のテストであればもっと早く簡単に発見できたはずです。砂時計パターンは、緊密な結合により、個々の依存関係を分離してインスタンス化することが困難な場合に発生します。

![fig11-4](../img/Fig11-4.png)

Figure 11-4. テストスイートのアンチパターン

私たちが推奨するテストの組み合わせは、エンジニアリングの生産性と製品の信頼性という2つの主要な目標によって決まります。ユニットテストを優先することで、開発プロセスの早い段階で高い信頼性を得ることができます。大規模なテストは、製品が開発される際の健全性をチェックするためのものであり、バグを発見するための主要な手段と見なすべきではありません。

あなた自身の組み合わせを考えると、異なるバランスが必要になるかもしれません。統合テストを重視した場合、テストスイートの実行には時間がかかるが、コンポーネント間の問題をより多く捕捉できることがわかるかもしれない。ユニットテストを重視した場合、テストスイートは非常に早く完了し、一般的なロジックのバグを多く検出することができます。しかし、ユニットテストでは、異なるチームが開発した2つのシステム間の契約のような、コンポーネント間の相互作用を検証することはできません。優れたテストスイートには、アーキテクチャや組織の現実に適した、さまざまなテストのサイズとスコープが混在しています。

### ビヨンセの法則

新入社員を指導する際に、どのような行動や特性を実際にテストする必要があるのか、という質問をよく受けます。率直な答えは、「壊したくないものはすべてテストする」です。言い換えれば、あるシステムが特定の動作をすることを確信したい場合、それを確認する唯一の方法は、そのための自動テストを書くことです。これには、パフォーマンス、動作の正しさ、アクセシビリティ、セキュリティのテストなど、一般的なものがすべて含まれます。また、システムが障害をどのように処理するかをテストするような、目立たない特性も含まれます。

私たちは、この一般的な考え方を「ビヨンセ・ルール」と呼んでいます。簡潔に言うと、次のようになります。"If you like it, then you shoulda put a test on it." ビヨンセ・ルールは、コードベース全体の変更に責任を持つインフラストラクチャ・チームでよく唱えられます。関連性のないインフラストラクチャの変更がすべてのテストに合格しても、チームの製品が壊れてしまった場合、あなたはそれを修正し、追加のテストを追加する責任があります。

----

### 故障を想定したテスト

システムが考慮しなければならない最も重要な状況の一つは、失敗です。失敗は避けられませんが、システムが大惨事にどれだけ対応できるかを調べるために、実際の大惨事を待つのは苦痛のもとになります。失敗を待つのではなく、一般的な種類の失敗をシミュレートする自動テストを書きましょう。これには、ユニットテストにおける例外やエラーのシミュレーション、統合テストやエンドツーエンドテストにおけるRPC（Remote Procedure Call）のエラーや遅延の注入などが含まれます。また、カオスエンジニアリングのような技術を用いて、実際の本番ネットワークに影響を与えるような大規模な障害を含めることもできます。悪条件に対する予測可能で制御された応答は、信頼性の高いシステムの特徴です。

----

### コードカバレッジについて

コードカバレッジとは、機能コードのどの行がどのテストによって実行されたかを示す指標です。100 行のコードがあり、そのうちの 90 行をテストが実行した場合、コードカバレッジは 90% となります(*7)。 コードカバレッジはテストの品質を理解するための金字塔のように語られることがありますが、これは少々残念なことです。多くのコードラインをいくつかのテストで実行することは可能ですが、それぞれのラインが何か有用なことをしているかどうかはチェックできません。これは、コードカバレッジが、ある行が呼び出されたことを測定しているだけで、その結果何が起こったかを測定していないからです。(大規模なテストを実行したときに発生するカバレッジの膨張を避けるために、小さなテストでのみカバレッジを測定することをお勧めします)。

コードカバレッジのさらに厄介な問題は、他の測定基準と同様に、すぐにそれ自体が目標となってしまうことです。例えば、80% というように、期待されるコードカバレッジの基準を設定することがよくあります。最初は、それは非常に合理的に聞こえます。確かに、少なくともその程度のカバレッジは欲しいものです。実際には、80％を床のように扱うのではなく、エンジニアが天井のように扱うことになります。やがて、80％以上のカバー率でないと変更ができなくなってしまいます。結局のところ、指標が要求する以上の仕事をする必要はないのです。

テストスイートの品質にアプローチするためのより良い方法は、テストされる動作について考えることです。顧客が期待する動作がすべて動作するという自信がありますか？依存関係にある変更をキャッチできる自信がありますか？あなたのテストは安定していて信頼できますか？このような質問は、テストスイートをより全体的に考えるためのものです。ハードウェアとのインタラクションをテストするのが難しい製品や、膨大なデータセットを扱う製品など、製品やチームはそれぞれ異なります。テストの数が足りているか」という問いに一つの数字で答えようとすると、多くの文脈を無視してしまい、役に立つことはまずありません。コードカバレッジは、テストされていないコードをある程度把握することができますが、自分のシステムがどれだけテストされているかを批判的に考えることの代用にはなりません。

## Googleスケールでのテスト

ここまでの説明の多くは、ほぼすべての規模のコードベースに適用できます。しかし、ここでは非常に大きな規模でのテストから学んだことについて、少し時間を割いてみたいと思います。Google でのテストの仕組みを理解するには、Google の開発環境を理解する必要があります。最も重要な事実は、Google のコードのほとんどが単一のモノリシックリポジトリ (monorepo) に保管されていることです。Googleが運営するすべての製品やサービスのコードのほとんどすべての行が、すべて1つの場所に保管されています。現在、リポジトリには20億行以上のコードが保管されています。

Googleのコードベースでは、毎週2,500万行近くの変更が行われています。そのうちのおよそ半分は、モノレポで働く何万人ものエンジニアが行っており、残りの半分は、構成の更新や大規模な変更（第22章）という形で、自動化されたシステムが行っています。それらの変更の多くは、当面のプロジェクトの外から開始されます。私たちは、エンジニアがコードを再利用することに対して、あまり制限を設けていません。

私たちのコードベースがオープンであることは、誰もがコードベースに責任を持つことができる共同所有のレベルを促進します。このようなオープン性の利点のひとつは、自分が使っている製品やサービスのバグを、文句を言う代わりに直接修正できることです（もちろん、承認を得てからですが）。これはまた、誰かが所有しているコードベースの一部に、多くの人が変更を加えることを意味します。

Googleが少し変わっているもう一つの点は、リポジトリのブランチを使うチームがほとんどないことです。すべての変更はリポジトリヘッドにコミットされ、誰もがすぐに見ることができます。さらに、すべてのソフトウェアのビルドは、テストインフラが検証した最後のコミットされた変更を使用して実行されます。製品やサービスが構築されると、それを実行するために必要なほぼすべての依存関係もソースから構築され、それもリポジトリのヘッドから構築されます。Googleは、この規模のテストをCIシステムで管理しています。GoogleのCIシステムの重要なコンポーネントの1つは、TAP（Test Automated Platform）です。

  TAPとGoogleのCIの考え方については、第23章を参照してください。

Googleのエンジニアリング環境は、Googleの規模、モノレポ、提供している製品の数など、どれをとっても複雑です。毎週、何百万行もの変更が行われ、何十億ものテストケースが実行され、何万ものバイナリがビルドされ、何百もの製品がアップデートされています......複雑とはこのことです。

### 大規模なテストスイートの落とし穴

コードベースが成長すると、必然的に既存のコードに変更を加える必要が出てきます。自動化されたテストの書き方が悪いと、そのような変更を行うことが難しくなります。脆弱なテストとは、期待される結果を過剰に指定したり、膨大で複雑な定型文に頼ったりするもので、実際には変更を妨げるものです。このようなテストは、関係のない変更が加えられた場合でも失敗することがあります。

もしあなたが、ある機能に5行の変更を加えた後に、何十もの無関係な壊れたテストを見つけたことがあるなら、あなたは脆いテストの摩擦を感じたことがあるでしょう。時間が経つにつれ、この摩擦によってチームはコードベースを健全に保つために必要なリファクタリングを行うことを躊躇するようになります。以降の章では、テストの堅牢性と品質を向上させるための戦略について説明します。

テストが脆弱になる原因としては、モックオブジェクトの誤用が挙げられます。Googleのコードベースは、モックフレームワークの乱用によって非常に大きな被害を受けており、一部のエンジニアは「もうモックはいらない！」と宣言しています。これは強い主張ですが、モックオブジェクトの限界を理解することは、モックオブジェクトの誤用を避けるために役立ちます。

  モックオブジェクトを効果的に使用する方法については、第13章を参照してください。

脆弱なテストによって生じる摩擦に加えて、より多くのテスト・スイートは実行速度が遅くなります。テストスイートが遅くなると、実行される頻度が減り、得られる利益も少なくなります。私たちはテストスイートを高速化するために、実行の並列化や高速なハードウェアの使用など、さまざまなテクニックを駆使しています。しかし、このようなテクニックを使っても、個々に遅いテストケースがたくさんあると、結局はその影響を受けてしまいます。

テストが遅くなる原因はさまざまです。例えば、システムの大部分を起動したり、実行前にエミュレータを起動したり、大規模なデータセットを処理したり、異なるシステムが同期するのを待ったりすることがあります。テストの開始時は十分に速くても、システムの成長とともに遅くなることがよくあります。例えば、1つの依存関係を対象とした統合テストでは5秒で応答していたのが、数年後には12のサービスに依存するようになり、同じテストに5分かかるようになったとします。

また、`sleep()`や`setTimeout()`などの関数で不必要な速度制限をかけることで、テストが遅くなることもあります。これらの関数の呼び出しは、非決定論的な動作の結果をチェックする前に、素朴なヒューリスティクスとして使われることがよくあります。しかし、広く使われているユーティリティーに「待機とチェック」が組み込まれていると、テストスイートを実行するたびに数分のアイドルタイムが追加されることになります。より良い解決策は、マイクロ秒に近い頻度で状態遷移のために積極的にポーリングすることです。これに、テストが安定した状態に到達できなかった場合のタイムアウト値を組み合わせることができます。

テストスイートを決定論的かつ高速に保つことができなければ、生産性の障害となってしまいます。Googleでは、このようなテストに遭遇したエンジニアは、速度低下を回避する方法を見つけており、中には変更を送信する際にテストを完全にスキップする人もいます。もちろん、これは危険な行為であり、控えるべきですが、テストスイートが利益よりも害をもたらしているのであれば、テストがあってもなくても、最終的にはエンジニアは仕事を終わらせる方法を見つけるでしょう。

大規模なテストスイートと共存するための秘訣は、敬意を持ってそれを扱うことです。エンジニアが自分のテストに関心を持つようにインセンティブを与えましょう。しっかりとしたテストができたときには、優れた機能を立ち上げたときと同じくらいの報酬を与えましょう。適切なパフォーマンス目標を設定し、遅いテストや限界のあるテストをリファクタリングします。基本的には、テストをプロダクションコードのように扱います。簡単な変更でも自ずと時間がかかるようになったら、テストのもろさを改善することに力を注ぎます。

適切な文化を育てることに加えて、テストのインフラに投資し、リンターやドキュメント、あるいは悪いテストを書きにくくするためのその他の支援を行います。サポートするフレームワークやツールの数を減らして、改善にかける時間を効率化する(*8) テストの管理を容易にすることに投資しなければ、最終的にエンジニアはテストを持つ価値がないと判断するだろう。

## Googleにおけるテストの歴史

Googleがどのようにテストに取り組んでいるかを説明してきましたが、どのようにしてここまで来たのかを知ることは有益なことかもしれません。前述したように、Googleのエンジニアは自動テストの価値を必ずしも認めていませんでした。実際、2005年までは、テストは規律ある実践というよりも、好奇心に近いものでした。ほとんどのテストは、手作業で行われていました。しかし、2005年から2006年にかけて、テスト革命が起こり、ソフトウェアエンジニアリングへの取り組み方が変わりました。その影響は今でも社内に響き渡っています。

そのきっかけとなったのが、本章の冒頭で触れたGWSプロジェクトの経験です。自動化されたテストがいかに強力であるかを明らかにしたのです。2005年にGWSが改良された後、その手法は全社的に普及し始めました。ツールは原始的なものだった。しかし、"Testing Grouplet "と呼ばれるようになった有志たちは、それにもめげませんでした。

自動テストを社内に浸透させるためには、3つの重要な取り組みがあった。オリエンテーションクラス」、「Test Certifiedプログラム」、「トイレでテスト」である。それぞれが全く違った形で影響を与え、Googleのエンジニア文化を変えていったのです。

### オリエンテーションクラス

Googleの初期のエンジニアリングスタッフの多くがテストを敬遠していたにもかかわらず、Googleの自動テストの先駆者たちは、会社の成長速度に合わせて、新しいエンジニアが既存のチームメンバーをすぐに上回ってしまうことを知っていました。もし社内の新入社員全員にテストを実施することができれば、文化的な変化をもたらす非常に効果的な手段となるでしょう。幸いなことに、昔も今も、エンジニアの新入社員が必ず通る「オリエンテーション」という関門がある。

初期のグーグルのオリエンテーションでは、医療手当やGoogle検索の仕組みなどが説明されていたが、2005年からは、自動テストの価値について1時間にわたって説明されるようになった(*9)。 このクラスでは、生産性の向上、ドキュメントの改善、リファクタリングのサポートなど、テストのさまざまなメリットが説明された。また、良いテストの書き方についても説明された。当時、多くのNoogler（新米Googler）にとって、このような授業はこのような内容に触れる最初の機会だった。最も重要なのは、これらのアイデアがすべて、会社の標準的な慣習であるかのように提示されていたことだ。新入社員たちは、自分たちがトロイの木馬になって、何も知らないチームにこのアイデアを忍ばせているとは知らなかった。

オリエンテーション後にチームに参加したNooglerたちは、テストを書き始め、テストをしないチームの人たちに質問をするようになりました。わずか1〜2年の間に、テストを教えてもらったエンジニアの人口が、テストをする前の文化的なエンジニアの人口を上回るようになりました。その結果、多くの新しいプロジェクトが正しいスタートを切れるようになりました。

今ではテストは業界で広く行われるようになり、ほとんどの新入社員は自動テストへの期待をしっかりと持って入社してきます。それでも、オリエンテーションクラスでは、テストについての期待を設定し、Google以外でのテストについてNooglerが知っていることと、非常に大きくて非常に複雑なコードベースでテストを行うことの難しさを結びつけています。

### 認証されたテスト

当初、私たちのコードベースの大規模で複雑な部分は、優れたテスト手法に対して抵抗を感じていました。プロジェクトの中には、コードの品質が低く、テストすることがほとんど不可能なものもありました。プロジェクトに明確な道筋を示すために、テストグループレットは「Test Certified」と呼ばれる認証プログラムを考案しました。「Test Certified」は、テストプロセスの成熟度を把握する方法をチームに提供し、さらに重要なこととして、テストプロセスを改善するための手順書を提供することを目的としています。

このプログラムは5つのレベルで構成されており、各レベルではチームのテスト衛生状態を改善するための具体的な行動が求められる。各レベルは、それぞれのステップアップが四半期以内に達成できるように設計されており、Googleの社内計画のケイデンスに都合よく適合していた。

テスト認証レベル1では、継続的なビルドの設定、コードカバレッジのトラッキングの開始、すべてのテストの小・中・大の分類、不具合のあるテストの特定（必ずしも修正する必要はない）、迅速に実行できる（必ずしも包括的ではない）テストのセットの作成といった基本的な内容が含まれています。レベルが上がるごとに、"壊れたテストを含むリリースはしない"、"すべての非決定論的テストを削除する "などの課題が追加されました。レベル5では、すべてのテストが自動化され、高速テストがすべてのコミットの前に実行され、すべての非決定性が除去され、すべての動作がカバーされていた。社内のダッシュボードには、各チームのレベルが表示され、社会的なプレッシャーとなった。チーム同士が競争してレベルアップするまでには時間がかかりませんでした。

2015年にTest Certifiedプログラムが自動化されたアプローチに取って代わられるまでに（pHについては後述します）、1,500以上のプロジェクトがテスト文化の改善に貢献しました。

### トイレでテスト

テスティンググループレットがGoogleのテストを改善するために用いた方法の中で、「Testing on the Toilet」（TotT）ほど奇抜なものはなかっただろう。TotTの目的はいたってシンプルで、テストに対する意識を全社的に高めることだった。問題は、世界中に社員が散らばっている会社で、それを実現するための最良の方法は何かということだ。

テスト部会では、定期的にメールマガジンを配信することも検討したが、Googleでは大量のメールを処理するため、ノイズに紛れてしまう可能性があった。そこで誰かが提案したのが、トイレの個室にチラシを貼るという冗談のようなアイデア。トイレは誰もが一日に一度は必ず訪れる場所です。

2006年4月、Pythonのテストを改善する方法を網羅した短い文章が、Google中のトイレの個室に現れました。この最初のエピソードは、ボランティアの小さなバンドによって投稿されました。反応は賛否両論でした。パーソナルスペースの侵害と見なし、強く反発する人もいました。メーリングリストにはたくさんの苦情が寄せられたが、TOTTの制作者たちは満足していた。苦情を言っている人たちが、まだテストの話をしているのだから。

結局、騒動は収まり、TOTTはグーグルの文化として定着していったのである。現在までに、全社のエンジニアが数百のエピソードを制作しており、テストに関するあらゆる側面を網羅しています。新しいエピソードが出るのを心待ちにしているエンジニアもおり、中にはボランティアで自分のビルの周りにエピソードを掲示する人もいます。各エピソードは意図的に1ページにまとめられており、著者は最も重要で実行可能なアドバイスに焦点を当てています。良いエピソードは、エンジニアがすぐにデスクに持ち帰って試せるものです。

皮肉なことに、プライベートな場所で発行されているにもかかわらず、『TOTT』は世間に大きな影響を与えている。外部からの訪問者のほとんどが、訪問中にエピソードを目にしています。そのような出会いから、「グーグルはいつもコードのことを考えているようだね」という面白い会話が生まれることもあります。さらに、TOTTのエピソードはブログのネタにもなります。これは、TOTTの原作者が早くから気づいていたことです。これは、TOTTの作者が早くから気づいていたことで、軽く編集したものを公開することで、私たちの経験を業界全体で共有することができるようになったのです。

冗談で始めたにもかかわらず、TotTはTesting Groupletが始めたテストの取り組みの中で、最も長く続いており、最も大きな影響を与えている。

### 現在のテスト文化

現在のGoogleのテスト文化は、2005年からずいぶんと進歩している。Nooglerたちは今でもテストに関するオリエンテーションクラスに参加しているし、TotTはほぼ毎週配布されている。しかし、テストに対する期待は、日々の開発者のワークフローの中により深く浸透している。

Googleでは、コードを変更するたびにコードレビューを受けることが義務付けられている。そして、すべての変更には、機能コードとテストの両方が含まれることが求められる。レビュー担当者は、その両方の品質と正しさをレビューすることが求められます。実際のところ、テストが含まれていない変更をブロックすることは完全に合理的です。

Test Certifiedに代わるものとして、あるエンジニアリング生産性向上チームが最近、Project Health（pH）というツールを発表しました。pHツールは、テストカバレッジやテストレイテンシーなど、プロジェクトの健全性に関する数多くの指標を継続的に収集し、社内で公開しています。 pHは、1（最悪）から5（最良）のスケールで測定されます。pH-1のプロジェクトは、チームが対処すべき問題と見なされます。継続的なビルドを行っているほとんどのチームは、自動的にpHスコアを取得している。

テストは、時を経て、Googleのエンジニア文化に欠かせないものとなっています。Googleでは、社内のエンジニアにテストの価値を伝えるために様々な方法を用いています。トレーニング、穏やかな働きかけ、メンターシップ、そしてもちろん少しの切磋琢磨を組み合わせて、テストは全員の仕事であるという明確な期待を持たせています。

なぜ、テストの作成を義務付けることから始めなかったのでしょうか？

テストグループレットは、シニアリーダーにテストの義務化を求めることを検討しましたが、すぐに断念しました。コードを開発する方法を強制することは、Googleの文化に著しく反しており、強制されるアイデアとは無関係に、進歩を遅らせる可能性がありました。成功したアイデアは広まるという信念があったので、成功を実証することに重点を置いた。

エンジニアが自分でテストを書くことを決めているということは、そのアイデアを完全に受け入れているということであり、たとえ誰にも強制されていなくても、正しいことをやり続ける可能性があるということだ。

## 自動テストの限界

自動テストは、すべてのテスト作業に適しているわけではありません。例えば、検索結果の品質をテストするには、人間の判断が必要な場合があります。私たちは、サーチクオリティーレイターが実際のクエリを実行し、その印象を記録することで、ターゲットを絞った社内調査を行っています。同様に、音声や映像の品質の微妙な違いを自動テストで把握することは難しいため、電話やビデオ通話システムの性能評価には人間の判断を用いることが多いです。

また、定性的な判断だけでなく、人間が得意とするクリエイティブな評価もあります。例えば、複雑なセキュリティの脆弱性を発見することは、自動化されたシステムよりも人間の方が得意とするところです。人間が欠陥を発見して理解した後は、GoogleのCloud Security Scannerのような自動セキュリティテストシステムに追加して、継続的かつ大規模に実行することができます。

この手法をより一般化した言葉として、「探索的テスト」があります。探索的テストとは、基本的に創造的な試みであり、テスト対象のアプリケーションを、予想外の手順を実行したり、予想外のデータを挿入したりして、壊すべきパズルとして扱います。探索的テストでは、発見すべき具体的な問題点は最初は不明です。一般的に見過ごされているコードパスや、アプリケーションからの通常とは異なる反応を探ることで、徐々に問題点が明らかになっていきます。セキュリティの脆弱性の検出と同様に、探索的テストで問題が発見されたら、将来のリグレッションを防ぐために自動テストを追加する必要があります。

よく理解されている動作をカバーするために自動テストを使用することで、人間のテスターの高価で質的な努力を、製品の最も価値のある部分に集中させることができ、その過程で彼らを退屈させないようにすることができます。

## 結論

開発者主導の自動テストの導入は、Googleにおいて最も変革をもたらしたソフトウェアエンジニアリング手法の一つです。これにより、大規模なシステムを大規模なチームで、これまで考えられなかったような速さで構築できるようになりました。また、技術的な変化のペースが速くなっても、それに対応できるようになりました。この15年間で、Googleはエンジニアリング文化を変革し、テストを文化的な規範とすることに成功しました。この旅が始まってから会社の規模が100倍になったにもかかわらず、品質とテストに対する当社のコミットメントは、これまで以上に強固なものとなっています。

この章では、Googleがテストについてどのように考えているかを説明しています。次の数章では、優れた、安定した、信頼性の高いテストを書くとはどういうことなのかということについて、私たちの理解を深めてくれるいくつかの重要なトピックについてさらに深く掘り下げていきます。Googleで最も一般的なテストであるユニットテストについて、何を、なぜ、どのように行うのかを説明します。フェイキング、スタッビング、インタラクション・テストなどのテクニックを使って、テストでテスト・ダブルを効果的に使用する方法についても議論します。最後に、Googleのような大規模で複雑なシステムをテストする際の課題について説明します。

この3つの章を終える頃には、私たちが使用しているテスト戦略について、さらに重要なこととして、なぜその戦略を使用しているのかについて、より深く明確なイメージを持つことができるでしょう。


## TL;DRs

- 自動化されたテストは、ソフトウェアの変更を可能にするための基盤となります。
- テストを拡張するには、自動化が必要です。
- 健全なテストカバレッジを維持するには、バランスのとれたテストスイートが必要です。
- "気に入ったのなら、その上にテストを置くべきだった。"
- 組織のテスト文化を変えるには時間がかかる。







----

1 「Defect Prevention: Reducing Costs and Enhancing Quality」を参照。
2 "Failure at Dhahran "参照。
3 異なるブラウザや言語で正しい動作をさせることは、また別の話です。しかし、最終的なユーザー体験は誰もが同じであることが理想です。
4 技術的には、Googleのテストには、small、medium、large、 enormousの4つのサイズがあります。しかし、大と小の違いは歴史的に見ても微妙なもので、本書では大についての記述は大の概念に当てはめています。
5 このポリシーには少しだけ余裕があります。密閉型のインメモリー実装を採用しているテストであれば、ファイルシステムにアクセスすることができます。
6 Mike Cohn, Succeeding with Agile: Software Development Using Scrum (New York: Addison-Wesley Professional, 2009).
7 カバレッジにはさまざまな種類（ライン、パス、ブランチなど）があり、それぞれがどのコードがテストされたかについて異なることを示していることに留意してください。この例では、ラインカバレッジを使用しています。
8 Google がサポートしている各言語には、標準的なテストフレームワークと標準的なモッキング/スタブライブラリがあります。1つのインフラが、コードベース全体のすべての言語でほとんどのテストを実行する。
9 このクラスは非常に成功したため、現在も更新版が教えられている。9 このクラスは非常に成功したため、現在も最新版が教えられている。実際、このクラスは、グーグルの歴史の中で最も長く続いているオリエンテーションクラスの一つである。

