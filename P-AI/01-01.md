[UP](README.md)

## フィードフォワード分類ネットワーク

フィードフォワード分類ネットワークは、深層ニューラルネットワークの一種で、複数の隠れニューロン層を持つことができます。この例では、隣接する層は完全に接続されています（隣接する層のすべてのニューロンが接続されています）。DL4Jライブラリは、大規模な問題にも対応できるように設計されており、GPUがあればそれを利用することができます。

一般的には、不必要に複雑なネットワーク・アーキテクチャよりも、問題を解決できるシンプルなネットワーク・アーキテクチャの方が良いとされています。シンプルなアーキテクチャから始めて、必要に応じてレイヤーや異なるレイヤータイプ、並列モデルを追加していくことができます。フィードフォワードネットワークのモデルの複雑さは、隠れた層のニューロンの数と、隠れ層の数の2つの次元があります。隠れ層のニューロンの数が多すぎると、トレーニングデータが事実上記憶されてしまい、トレーニングに使用していないデータサンプル（アウトオブサンプルデータと呼ばれる）でのパフォーマンスが低下します。実際には、独立したテストデータでモデルの精度が低下するまで、隠れニューロンの数を減らして「ネットワークを飢えさせ」ます。その後、隠れた層のニューロンの数を少しずつ増やしていきます。この手法は、モデルが単にトレーニングデータを記憶してしまうこと（オーバーフィッティング問題）を防ぐのに役立ちます。

この例では、ウィスコンシン大学のがんのトレーニングデータとテストデータのセットを読み込み（37～53行目）、モデルを作成し（53～79行目）、トレーニングを行い（81行目）、テストを行います（82～94行目）。

23行目では、各層の隠れユニットの数を増やすことができます（より複雑な問題の場合に行うことがあります）。隠れ層を追加するには、68～75行目を繰り返します（層のインデックスを1から2に増やします）。この例では、Clojureのデータ型ではなく、主にJavaのデータ型を扱っていることに注意してください。JenaのRDF/SPARQLライブラリを使用する後の章では、Javaの値をClojureの値に変換します。

```Clojure
(ns deeplearning-dl4j-clj.wisconsin-data
  (:import [org.datavec.api.split FileSplit]
           [org.deeplearning4j.datasets.datavec
            RecordReaderDataSetIterator]
           [org.datavec.api.records.reader.impl.csv
            CSVRecordReader]
           [org.deeplearning4j.nn.conf
            NeuralNetConfiguration$Builder]
           [org.deeplearning4j.nn.conf.layers
            OutputLayer$Builder DenseLayer$Builder]
           [org.deeplearning4j.nn.weights WeightInit]
           [org.nd4j.linalg.activations Activation]
           [org.nd4j.linalg.lossfunctions
            LossFunctions$LossFunction]
           [org.deeplearning4j.optimize.listeners
            ScoreIterationListener]
           [org.deeplearning4j.nn.multilayer
            MultiLayerNetwork]
           [java.io File]
           [org.nd4j.linalg.learning.config Adam Sgd
            AdaDelta AdaGrad AdaMax Nadam NoOp]))

(def numHidden 3)
(def numOutputs 1)
(def batchSize 64)

(def initial-seed (long 33117))

(def numInputs 9)
(def labelIndex 9)
(def numClasses 2)

(defn -main
  "Using DL4J with Wisconsin data"
  [& args]
  (let [recordReader (new CSVRecordReader)
        _ (. recordReader   ; トレーニングデータの読み込み
             initialize
             (new FileSplit
                  (new File "data/", "training.csv")))
        trainIter
        (new RecordReaderDataSetIterator
             recordReader batchSize labelIndex numClasses)
        recordReaderTest (new CSVRecordReader)
        _ (. recordReaderTest   ; テストデータの読み込み
             initialize
             (new FileSplit
                  (new File "data/", "testing.csv")))
        testIter
        (new RecordReaderDataSetIterator
             recordReaderTest batchSize labelIndex
             numClasses)
        conf (->   ; モデルの作成
              (new NeuralNetConfiguration$Builder)
              (.seed initial-seed)
              (.activation Activation/TANH)
              (.weightInit (WeightInit/XAVIER))
              (.updater (new Sgd 0.1))
              (.l2 1e-4)
              (.list)
              (.layer
               0,
               (-> (new DenseLayer$Builder)
                   (.nIn numInputs)
                   (.nOut numHidden)
                   (.build)))
              (.layer   ; 隠れユニットの数を増やす(隠れ層を追加するには層のインデックスを増やしてこの部分をくりかえす)
               1,
               (-> (new OutputLayer$Builder
                        LossFunctions$LossFunction/MCXENT)
                   (.nIn numHidden)
                   (.nOut numClasses)
                   (.activation Activation/SOFTMAX)
                   (.build)))
              (.build))
        model (new MultiLayerNetwork conf)
        score-listener (ScoreIterationListener. 100)]
    (. model init)
    (. model setListeners (list score-listener))
    (. model fit trainIter 10)  ; トレーニングの実行
    (while (. testIter hasNext)   ; テストの実行
      (let [ds (. testIter next)
            features (. ds getFeatures)
            labels (. ds getLabels)
            predicted (. model output features false)]
        ;; 26 test samples in data/testing.csv:
        (doseq [i (range 0 52 2)]
          (println
           "desired output: [" (. labels getDouble i)
           (. labels getDouble (+ i 1)) "]"
           "predicted output: ["
           (. predicted getDouble i)
           (. predicted getDouble (+ i 1)) "]"))))))
```

トレーニングデータとテストデータを別々に用意していることに注目してください。なぜなら、ネットワークに十分なメモリ容量がある（つまり、十分な隠れユニットと各隠れ層に十分なニューロンがある）と仮定すれば、トレーニングデータを認識したときのパフォーマンスは常に良好なはずだからです。ネットワークに十分な記憶容量があると仮定すると、トレーニングデータの認識性能は常に良好なはずです。

次のプログラム出力は、ターゲット（正しい出力）と、学習したモデルが予測した出力を示しています。

target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 0.0 1.0 ] predicted : [ 0.39 0.61 ]
target: [ 1.0 0.0 ] predicted : [ 0.91 0.09 ]
target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 1.0 0.0 ] predicted : [ 0.96 0.04 ]
target: [ 1.0 0.0 ] predicted : [ 0.95 0.05 ]
target: [ 1.0 0.0 ] predicted : [ 0.95 0.05 ]
target: [ 0.0 1.0 ] predicted : [ 0.21 0.79 ]
target: [ 1.0 0.0 ] predicted : [ 0.94 0.06 ]
target: [ 1.0 0.0 ] predicted : [ 0.92 0.08 ]
target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 1.0 0.0 ] predicted : [ 0.94 0.06 ]
target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 1.0 0.0 ] predicted : [ 0.96 0.04 ]
target: [ 0.0 1.0 ] predicted : [ 0.17 0.83 ]
target: [ 0.0 1.0 ] predicted : [ 0.17 0.83 ]
target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 0.0 1.0 ] predicted : [ 0.16 0.84 ]
target: [ 1.0 0.0 ] predicted : [ 0.95 0.05 ]
target: [ 1.0 0.0 ] predicted : [ 0.94 0.06 ]
target: [ 1.0 0.0 ] predicted : [ 0.92 0.08 ]
target: [ 1.0 0.0 ] predicted : [ 0.96 0.04 ]

これは簡単な例ですが、ClojureプロジェクトでDL4Jを使用したいと考えている方には十分でしょう。別のアプローチとしては、モデルコードをJavaで記述し、ClojureプロジェクトにJavaコードを埋め込む方法があります - 後の章でこの例を見ます。

[UP](README.md)

[NEXT](01-02.md)